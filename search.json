[
  {
    "objectID": "learner.html",
    "href": "learner.html",
    "title": "BigTabular learner",
    "section": "",
    "text": "The main function you probably want to use in this module is dask_learner. It will automatically create a TabularModel suitable for your data and infer the right loss function. See the BigTabular tutorial for an example of use in context.",
    "crumbs": [
      "BigTabular learner"
    ]
  },
  {
    "objectID": "learner.html#main-functions",
    "href": "learner.html#main-functions",
    "title": "BigTabular learner",
    "section": "Main functions",
    "text": "Main functions\n\nsource\n\nDaskLearner\nLearner for tabular data in Dask\nDaskLearner inherits from fast.ai’s TabularLearner. It works exactly as a normal Learner, the only difference is that it implements a predict method specific to work on a row of data.\n\nsource\n\n\ndask_learner\n\n dask_learner (dls:DataLoaders, layers:list=None, emb_szs:list=None,\n               config:dict=None, n_out:int=None, y_range:Tuple=None,\n               loss_func:callable|None=None,\n               opt_func:Optimizer|OptimWrapper=&lt;function Adam&gt;,\n               lr:float|slice=0.001, splitter:callable=&lt;function\n               trainable_params&gt;, cbs:Callback|MutableSequence|None=None,\n               metrics:callable|MutableSequence|None=None,\n               path:str|Path|None=None, model_dir:str|Path='models',\n               wd:float|int|None=None, wd_bn_bias:bool=False,\n               train_bn:bool=True, moms:tuple=(0.95, 0.85, 0.95),\n               default_cbs:bool=True)\n\nGet a Learner using dls, with metrics, including a TabularModel created using the remaining params.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndls\nDataLoaders\n\nDataLoaders containing fastai or PyTorch DataLoaders\n\n\nlayers\nlist\nNone\nSize of the layers generated by LinBnDrop\n\n\nemb_szs\nlist\nNone\nTuples of n_unique, embedding_size for all categorical features\n\n\nconfig\ndict\nNone\nConfig params for TabularModel from tabular_config\n\n\nn_out\nint\nNone\nFinal output size of the model\n\n\ny_range\nTuple\nNone\nLow and high for the final sigmoid function\n\n\nloss_func\ncallable | None\nNone\nLoss function. Defaults to dls loss\n\n\nopt_func\nOptimizer | OptimWrapper\nAdam\nOptimization function for training\n\n\nlr\nfloat | slice\n0.001\nDefault learning rate\n\n\nsplitter\ncallable\ntrainable_params\nSplit model into parameter groups. Defaults to one parameter group\n\n\ncbs\nCallback | MutableSequence | None\nNone\nCallbacks to add to Learner\n\n\nmetrics\ncallable | MutableSequence | None\nNone\nMetrics to calculate on validation set\n\n\npath\nstr | Path | None\nNone\nParent directory to save, load, and export models. Defaults to dls path\n\n\nmodel_dir\nstr | Path\nmodels\nSubdirectory to save and load models\n\n\nwd\nfloat | int | None\nNone\nDefault weight decay\n\n\nwd_bn_bias\nbool\nFalse\nApply weight decay to normalization and bias parameters\n\n\ntrain_bn\nbool\nTrue\nTrain frozen normalization layers\n\n\nmoms\ntuple\n(0.95, 0.85, 0.95)\nDefault momentum for schedulers\n\n\ndefault_cbs\nbool\nTrue\nInclude default Callbacks\n\n\n\nIf your data was built with fastai, you probably won’t need to pass anything to emb_szs unless you want to change the default of the library (produced by get_emb_sz), same for n_out which should be automatically inferred. layers will default to [200,100] and is passed to TabularModel along with the config.\nUse tabular_config to create a config and customize the model used. There is just easy access to y_range because this argument is often used.\nAll the other arguments are passed to Learner.\nThe following function gives the same result as valid_idx=list(range(800,1000)) in TabularDataLoaders. This is only the cases for a Dask dataframe with one partition.\n\ndef split_func(df): return pd.Series([False if i &gt;= 800 and i &lt; 1000 else True for i in range(len(df))])\n\n\npath = untar_data(URLs.ADULT_SAMPLE)\nddf = dd.from_pandas(pd.read_csv(path/'adult.csv'))\ncat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\ncont_names = ['age', 'fnlwgt', 'education-num']\nprocs = [DaskCategorify, DaskFillMissing, DaskNormalize]\ndls = DaskDataLoaders.from_ddf(ddf, path, procs=procs, cat_names=cat_names, cont_names=cont_names,\n                              y_names=\"salary\", train_mask_func=split_func, bs=64)\nlearn = dask_learner(dls)\n\n/home/stefan/Insync/OneDrive_personal/python_workspace/dev/tmp/bigtabular/bigtabular/core.py:203: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\n\nsource\n\n\nDaskLearner.predict\n\n DaskLearner.predict (row:pandas.core.series.Series)\n\nPredict on a single sample\n\n\n\n\nType\nDetails\n\n\n\n\nrow\npd.Series\nFeatures to be predicted\n\n\n\nWe can pass in an individual row of data into our TabularLearner’s predict method. It’s output is slightly different from the other predict methods, as this one will always return the input as well:\n\nrow, clas, probs = learn.predict(ddf.head().iloc[0])\n\n\n\n\n\n\n\n\n\nrow\n\n\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\n\n\n\n\n0\nPrivate\nAssoc-acdm\nMarried-civ-spouse\n#na#\nWife\nWhite\nFalse\n49.0\n101320.001686\n12.0\n\n\n\n\n\n\n\n\nclas, probs\n\n(tensor(0), tensor([0.5152, 0.4848]))",
    "crumbs": [
      "BigTabular learner"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "BigTabular data",
    "section": "",
    "text": "The main class to get your data ready for model training is TabularDataLoaders and its factory methods. Checkout the BigTabular tutorial for examples of use.\n\nsource\n\nDaskDataLoaders\n\n DaskDataLoaders (*loaders, path:str|pathlib.Path='.', device=None)\n\nBasic wrapper around DaskDataLoader with factory methods for large tabular datasets with Dask\nThis class should not be used directly, one of the factory methods should be preferred instead. All those factory methods accept as arguments:\n\ncat_names: the names of the categorical variables\ncont_names: the names of the continuous variables\ny_names: the names of the dependent variables\ny_block: the TransformBlock to use for the target\nvalid_idx: the indices to use for the validation set (defaults to a random split otherwise)\nbs: the batch size\nval_bs: the batch size for the validation DataLoader (defaults to bs)\nshuffle_train: if we shuffle the training DataLoader or not\nn: overrides the numbers of elements in the dataset\ndevice: the PyTorch device to use (defaults to default_device())\n\n\nsource\n\n\nDaskDataLoaders.from_ddf\n\n DaskDataLoaders.from_ddf (ddf:dd.DataFrame, path:str|Path='.',\n                           procs:list=None, cat_names:list=None,\n                           cont_names:list=None, y_names:list=None,\n                           y_block:TransformBlock=None,\n                           train_mask_func:callable=None, bs:int=64,\n                           shuffle_train:bool=None, shuffle:bool=True,\n                           val_shuffle:bool=False, n:int=None,\n                           device:torch.device=None, drop_last:bool=None,\n                           val_bs:int=None)\n\nCreate TabularDataLoaders from df in path using procs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nddf\ndd.DataFrame\n\nA Dask dataframe\n\n\npath\nstr | Path\n.\nLocation of df, defaults to current working directory\n\n\nprocs\nlist\nNone\nList of TabularProcs\n\n\ncat_names\nlist\nNone\nColumn names pertaining to categorical variables\n\n\ncont_names\nlist\nNone\nColumn names pertaining to continuous variables\n\n\ny_names\nlist\nNone\nNames of the dependent variables\n\n\ny_block\nTransformBlock\nNone\nTransformBlock to use for the target(s)\n\n\ntrain_mask_func\ncallable\nNone\nA function that creates a train/validation mask over a DataFrame\n\n\nbs\nint\n64\nBatch size\n\n\nshuffle_train\nbool\nNone\n(Deprecated, use shuffle) Shuffle training DataLoader\n\n\nshuffle\nbool\nTrue\nShuffle is currently ignored in DaskDataLoader\n\n\nval_shuffle\nbool\nFalse\nShuffle validation DataLoader\n\n\nn\nint\nNone\nSize of Datasets used to create DataLoader\n\n\ndevice\ntorch.device\nNone\nDevice to put DataLoaders\n\n\ndrop_last\nbool\nNone\nDrop last incomplete batch, defaults to shuffle. Currently ignored in DaskDataLoader\n\n\nval_bs\nint\nNone\nValidation batch size, defaults to bs\n\n\n\nLet’s have a look on an example with the adult dataset:\n\npath = untar_data(URLs.ADULT_SAMPLE)\ndf = pd.read_csv(path/'adult.csv', skipinitialspace=True)\nddf = dd.from_pandas(df)\nddf.head()\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nsalary\n\n\n\n\n0\n49\nPrivate\n101320\nAssoc-acdm\n12.0\nMarried-civ-spouse\n&lt;NA&gt;\nWife\nWhite\nFemale\n0\n1902\n40\nUnited-States\n&gt;=50k\n\n\n1\n44\nPrivate\n236746\nMasters\n14.0\nDivorced\nExec-managerial\nNot-in-family\nWhite\nMale\n10520\n0\n45\nUnited-States\n&gt;=50k\n\n\n2\n38\nPrivate\n96185\nHS-grad\nNaN\nDivorced\n&lt;NA&gt;\nUnmarried\nBlack\nFemale\n0\n0\n32\nUnited-States\n&lt;50k\n\n\n3\n38\nSelf-emp-inc\n112847\nProf-school\n15.0\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nMale\n0\n0\n40\nUnited-States\n&gt;=50k\n\n\n4\n42\nSelf-emp-not-inc\n82297\n7th-8th\nNaN\nMarried-civ-spouse\nOther-service\nWife\nBlack\nFemale\n0\n0\n50\nUnited-States\n&lt;50k\n\n\n\n\n\n\n\n\ncat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\ncont_names = ['age', 'fnlwgt', 'education-num']\nprocs = [DaskCategorify, DaskFillMissing, DaskNormalize]\n\nThe following function gives the same result as valid_idx=list(range(800,1000)) in TabularDataLoaders. This is only the cases for a Dask dataframe with one partition.\n\ndef split_func(df): return pd.Series([False if i &gt;= 800 and i &lt; 1000 else True for i in range(len(df))])\n\n\ndls = DaskDataLoaders.from_ddf(ddf, path, procs=procs, cat_names=cat_names, cont_names=cont_names, \n                                 y_names=\"salary\", train_mask_func=split_func, bs=64)\n\n/home/stefan/Insync/OneDrive_personal/python_workspace/dev/tmp/bigtabular/bigtabular/core.py:203: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\n\ndls.show_batch()\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\n\n\n\n\n0\nPrivate\nAssoc-acdm\nMarried-civ-spouse\n#na#\nWife\nWhite\nFalse\n49.0\n101320.001686\n12.0\n&gt;=50k\n\n\n1\nPrivate\nMasters\nDivorced\nExec-managerial\nNot-in-family\nWhite\nFalse\n44.0\n236745.998860\n14.0\n&gt;=50k\n\n\n2\nPrivate\nHS-grad\nDivorced\n#na#\nUnmarried\nBlack\nTrue\n38.0\n96185.001882\n10.0\n&lt;50k\n\n\n3\nSelf-emp-inc\nProf-school\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nFalse\n38.0\n112847.002752\n15.0\n&gt;=50k\n\n\n4\nSelf-emp-not-inc\n7th-8th\nMarried-civ-spouse\nOther-service\nWife\nBlack\nTrue\n42.0\n82297.004480\n10.0\n&lt;50k\n\n\n5\nPrivate\nHS-grad\nNever-married\nHandlers-cleaners\nOwn-child\nWhite\nFalse\n20.0\n63209.995727\n9.0\n&lt;50k\n\n\n6\nPrivate\nSome-college\nDivorced\n#na#\nOther-relative\nWhite\nFalse\n49.0\n44434.004384\n10.0\n&lt;50k\n\n\n7\nPrivate\n11th\nMarried-civ-spouse\n#na#\nHusband\nWhite\nFalse\n37.0\n138940.000568\n7.0\n&lt;50k\n\n\n8\nPrivate\nHS-grad\nMarried-civ-spouse\nCraft-repair\nHusband\nWhite\nFalse\n46.0\n328216.004421\n9.0\n&gt;=50k\n\n\n\n\n\n\nsource\n\n\nDaskDataLoaders.from_csv\n\n DaskDataLoaders.from_csv (csv:str|Path|io.BufferedReader, *args,\n                           skipinitialspace=True, header='infer',\n                           dtype_backend=None, storage_options=None,\n                           path:str|Path='.', procs:list=None,\n                           cat_names:list=None, cont_names:list=None,\n                           y_names:list=None, y_block:TransformBlock=None,\n                           train_mask_func:callable=None, bs:int=64,\n                           shuffle_train:bool=None, shuffle:bool=True,\n                           val_shuffle:bool=False, n:int=None,\n                           device:torch.device=None, drop_last:bool=None,\n                           val_bs:int=None)\n\nCreate TabularDataLoaders from csv file in path using procs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncsv\nstr | Path | io.BufferedReader\n\nA csv of training data\n\n\nargs\n\n\n\n\n\nskipinitialspace\nbool\nTrue\n\n\n\nheader\nstr\ninfer\n\n\n\ndtype_backend\nNoneType\nNone\n\n\n\nstorage_options\nNoneType\nNone\n\n\n\npath\nstr | Path\n.\nLocation of df, defaults to current working directory\n\n\nprocs\nlist\nNone\nList of TabularProcs\n\n\ncat_names\nlist\nNone\nColumn names pertaining to categorical variables\n\n\ncont_names\nlist\nNone\nColumn names pertaining to continuous variables\n\n\ny_names\nlist\nNone\nNames of the dependent variables\n\n\ny_block\nTransformBlock\nNone\nTransformBlock to use for the target(s)\n\n\ntrain_mask_func\ncallable\nNone\nA function that creates a train/validation mask over a DataFrame\n\n\nbs\nint\n64\nBatch size\n\n\nshuffle_train\nbool\nNone\n(Deprecated, use shuffle) Shuffle training DataLoader\n\n\nshuffle\nbool\nTrue\nShuffle is currently ignored in DaskDataLoader\n\n\nval_shuffle\nbool\nFalse\nShuffle validation DataLoader\n\n\nn\nint\nNone\nSize of Datasets used to create DataLoader\n\n\ndevice\ntorch.device\nNone\nDevice to put DataLoaders\n\n\ndrop_last\nbool\nNone\nDrop last incomplete batch, defaults to shuffle. Currently ignored in DaskDataLoader\n\n\nval_bs\nint\nNone\nValidation batch size, defaults to bs\n\n\n\n\ncat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\ncont_names = ['age', 'fnlwgt', 'education-num']\nprocs = [DaskCategorify, DaskFillMissing, DaskNormalize]\ndls = DaskDataLoaders.from_csv(path/'adult.csv', path=path, procs=procs, cat_names=cat_names, cont_names=cont_names, \n                                  y_names=\"salary\", train_mask_func=split_func, bs=64)\n\n/home/stefan/Insync/OneDrive_personal/python_workspace/dev/tmp/bigtabular/bigtabular/core.py:203: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\n\nsource\n\n\nDaskDataLoaders.test_dl\n\n DaskDataLoaders.test_dl (test_items, rm_type_tfms=None,\n                          process:bool=True, inplace:bool=False, **kwargs)\n\nCreate test DaskDataLoader from test_items using validation procs\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntest_items\n\n\nItems to create new test TabDataLoader formatted the same as the training data\n\n\nrm_type_tfms\nNoneType\nNone\nNumber of Transforms to be removed from procs\n\n\nprocess\nbool\nTrue\nApply validation TabularProcs to test_items immediately\n\n\ninplace\nbool\nFalse\nKeep separate copy of original test_items in memory if False\n\n\nkwargs\n\n\n\n\n\n\nExternal structured data files can contain unexpected spaces, e.g. after a comma. We can see that in the first row of adult.csv \"49, Private,101320, ...\". Often trimming is needed. Pandas has a convenient parameter skipinitialspace that is exposed by TabularDataLoaders.from_csv(). Otherwise category labels use for inference later such as workclass:Private will be categorized wrongly to 0 or \"#na#\" if training label was read as \" Private\". Let’s test this feature.\n\ntest_data = {\n    'age': [49], \n    'workclass': ['Private'], \n    'fnlwgt': [101320],\n    'education': ['Assoc-acdm'], \n    'education-num': [12.0],\n    'marital-status': ['Married-civ-spouse'], \n    'occupation': [''],\n    'relationship': ['Wife'],\n    'race': ['White'],\n}\ninput = dd.from_pandas(pd.DataFrame(test_data))\ntdl = dls.test_dl(input)\n\ntest_ne(0, tdl.dataset.items.compute().iloc[0]['workclass'])",
    "crumbs": [
      "BigTabular data"
    ]
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Tutorial: Tabular training with Dask",
    "section": "",
    "text": "To illustrate the tabular application, we will use the example of the Adult dataset where we have to predict if a person is earning more or less than $50k per year using some general data.\nThis is a small dataset that can easily be processed in-memorory by Pandas. In practice, fast.ai’s TabularPandas should be used when the data can be handled with Pandas. This tutorial is only to illustrate the functionality of bigtabular and to show the similarity to the fastai.tabular API. The guidance from Dask applies:\n\nDask DataFrames are often used either when …\n\nYour data is too big\nYour computation is too slow and other techniques don’t work\n\nYou should probably stick to just using pandas if …\n\nYour data is small\nYour computation is fast (subsecond)\nThere are simpler ways to accelerate your computation, like avoiding .apply or Python for loops and using a built-in pandas method instead.\n\n\n\nfrom fastai.tabular.all import *\nfrom bigtabular.core import *\nfrom bigtabular.data import *\nfrom bigtabular.learner import *\nimport dask.dataframe as dd\n\nWe can download a sample of this dataset with the usual untar_data command:\n\npath = untar_data(URLs.ADULT_SAMPLE)\npath.ls()\n\n(#3) [Path('/home/stefan/.fastai/data/adult_sample/export.pkl'),Path('/home/stefan/.fastai/data/adult_sample/adult.csv'),Path('/home/stefan/.fastai/data/adult_sample/models')]\n\n\nThen we can load the data into a Dask dataframe and have a look at how it is structured:\n\ndf = pd.read_csv(path/'adult.csv')\nddf = dd.from_pandas(df)\nddf.head()\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nsalary\n\n\n\n\n0\n49\nPrivate\n101320\nAssoc-acdm\n12.0\nMarried-civ-spouse\n&lt;NA&gt;\nWife\nWhite\nFemale\n0\n1902\n40\nUnited-States\n&gt;=50k\n\n\n1\n44\nPrivate\n236746\nMasters\n14.0\nDivorced\nExec-managerial\nNot-in-family\nWhite\nMale\n10520\n0\n45\nUnited-States\n&gt;=50k\n\n\n2\n38\nPrivate\n96185\nHS-grad\nNaN\nDivorced\n&lt;NA&gt;\nUnmarried\nBlack\nFemale\n0\n0\n32\nUnited-States\n&lt;50k\n\n\n3\n38\nSelf-emp-inc\n112847\nProf-school\n15.0\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nMale\n0\n0\n40\nUnited-States\n&gt;=50k\n\n\n4\n42\nSelf-emp-not-inc\n82297\n7th-8th\nNaN\nMarried-civ-spouse\nOther-service\nWife\nBlack\nFemale\n0\n0\n50\nUnited-States\n&lt;50k\n\n\n\n\n\n\n\nSome of the columns are continuous (like age) and we will treat them as float numbers we can feed our model directly. Others are categorical (like workclass or education) and we will convert them to a unique index that we will feed to embedding layers. We can specify our categorical and continuous column names, as well as the name of the dependent variable in DaskDataLoaders factory methods:\n\ndls = DaskDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [DaskCategorify, DaskFillMissing, DaskNormalize])\n\n/home/stefan/Insync/OneDrive_personal/python_workspace/dev/tmp/bigtabular/bigtabular/core.py:203: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\nThe last part is the list of pre-processors we apply to our data:\n\nDaskCategorify is going to take every categorical variable and make a map from integer to unique categories, then replace the values by the corresponding index.\nDaskFillMissing will fill the missing values in the continuous variables by the median of existing values (you can choose a specific value if you prefer)\nDaskNormalize will normalize the continuous variables (subtract the mean and divide by the std)\n\nThese processors are Dask compatible versions of Categorify, FillMissing and Normalize in fastai.tabular.\nTo further expose what’s going on below the surface, let’s rewrite this utilizing the TabularDask class. We will need to make one adjustment, which is defining how we want to split our data. By default the factory method above used a random 80/20 split, so we will do the same:\n\nsplit_func = RandomTrainMask()\n\n\nto = TabularDask(ddf, procs=[DaskCategorify, DaskFillMissing, DaskNormalize],\n                   cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n                   cont_names = ['age', 'fnlwgt', 'education-num'],\n                   y_names='salary',\n                   train_mask_func=split_func)\n\nBy comparison, to show the similarity between the APIs, this is the TabularPandas equivalent on which TabularDask is based:\n\nsplits = RandomSplitter(valid_pct=0.2)(range_of(df))\n\n\nto_ = TabularPandas(df, procs=[Categorify, FillMissing,Normalize],\n                    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n                    cont_names = ['age', 'fnlwgt', 'education-num'],\n                    y_names='salary',\n                    splits=splits)\n\n/home/stefan/anaconda3/envs/bigtabular/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n\n\nOnce we build our TabularDask object, our data is completely preprocessed as seen below:\n\nto.xs.head()\n\n\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\n\n\n\n\n0\n5\n8\n3\n0\n6\n5\n1\n0.763014\n-0.838956\n0.752354\n\n\n1\n5\n13\n1\n5\n2\n5\n1\n0.396491\n0.444738\n1.534279\n\n\n2\n5\n12\n1\n0\n5\n3\n2\n-0.043336\n-0.887631\n-0.029572\n\n\n3\n6\n15\n3\n11\n1\n2\n1\n-0.043336\n-0.729692\n1.925242\n\n\n4\n7\n6\n3\n9\n6\n3\n2\n0.249882\n-1.019274\n-0.029572\n\n\n\n\n\n\n\nNow we can build our DataLoaders again:\n\ndls = to.dataloaders(bs=64)\n\n/home/stefan/Insync/OneDrive_personal/python_workspace/dev/tmp/bigtabular/bigtabular/core.py:203: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\n\nLater we will explore why using TabularDask to preprocess will be valuable.\n\nThe show_batch method works the same as in fastai.tabular:\n\ndls.show_batch()\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\n\n\n\n\n0\nPrivate\nAssoc-acdm\nMarried-civ-spouse\n#na#\nWife\nWhite\nFalse\n49.0\n101320.001104\n12.0\n&gt;=50k\n\n\n1\nPrivate\nMasters\nDivorced\nExec-managerial\nNot-in-family\nWhite\nFalse\n44.0\n236746.000557\n14.0\n&gt;=50k\n\n\n2\nPrivate\nHS-grad\nDivorced\n#na#\nUnmarried\nBlack\nTrue\n38.0\n96185.000211\n10.0\n&lt;50k\n\n\n3\nSelf-emp-inc\nProf-school\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nFalse\n38.0\n112846.997183\n15.0\n&gt;=50k\n\n\n4\nSelf-emp-not-inc\n7th-8th\nMarried-civ-spouse\nOther-service\nWife\nBlack\nTrue\n42.0\n82296.999111\n10.0\n&lt;50k\n\n\n5\nPrivate\nSome-college\nDivorced\n#na#\nOther-relative\nWhite\nFalse\n49.0\n44434.004438\n10.0\n&lt;50k\n\n\n6\nPrivate\n11th\nMarried-civ-spouse\n#na#\nHusband\nWhite\nFalse\n37.0\n138940.000986\n7.0\n&lt;50k\n\n\n7\nSelf-emp-inc\nHS-grad\nMarried-civ-spouse\n#na#\nHusband\nWhite\nTrue\n36.0\n216710.998684\n10.0\n&gt;=50k\n\n\n8\nPrivate\nBachelors\nNever-married\n#na#\nOwn-child\nBlack\nFalse\n23.0\n529222.998504\n13.0\n&lt;50k\n\n\n\n\n\nWe can define a model using the dask_learner method. The DaskLearner class inherits from the TabularLearner class. When we define our model, fastai will try to infer the loss function based on our y_names earlier.\nNote: Sometimes with tabular data, your y’s may be encoded (such as 0 and 1). In such a case you should explicitly pass y_block = DaskCategoryBlock in your constructor so fastai won’t presume you are doing regression.\n\nlearn = dask_learner(dls, metrics=accuracy)\n\nAnd we can train that model with the fit_one_cycle method (the fine_tune method won’t be useful here since we don’t have a pretrained model).\n\nlearn.fit_one_cycle(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.367721\n0.358477\n0.838588\n01:02\n\n\n\n\n\nWe can then have a look at some predictions:\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\nsalary_pred\n\n\n\n\n0\n5\n12\n5\n7\n4\n5\n1\n-1.362819\n-1.200198\n-0.420534\n0\n0\n\n\n1\n5\n12\n3\n4\n1\n5\n1\n0.543100\n1.311777\n-0.420534\n1\n0\n\n\n2\n8\n13\n1\n0\n2\n5\n1\n1.276146\n0.798919\n1.534279\n0\n0\n\n\n3\n5\n10\n3\n11\n1\n5\n2\n0.469796\n0.740680\n-0.029572\n1\n1\n\n\n4\n5\n7\n1\n13\n2\n5\n2\n0.543100\n-0.684592\n-0.029572\n0\n0\n\n\n5\n5\n12\n4\n0\n4\n3\n2\n-0.703078\n10.223143\n-0.029572\n0\n0\n\n\n6\n5\n12\n3\n4\n1\n5\n1\n0.763014\n0.544722\n-0.420534\n1\n0\n\n\n7\n6\n13\n3\n5\n1\n5\n1\n1.202842\n0.310791\n1.534279\n0\n1\n\n\n8\n7\n16\n1\n0\n5\n5\n2\n0.616405\n0.226713\n-0.029572\n0\n0\n\n\n\n\n\nOr use the predict method on a row:\n\nrow, clas, probs = learn.predict(ddf.head().iloc[0])\n\n\n\n\n\n\n\n\n\nrow\n\n\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\n\n\n\n\n0\nPrivate\nAssoc-acdm\nMarried-civ-spouse\n#na#\nWife\nWhite\nFalse\n49.0\n101320.001104\n12.0\n\n\n\n\n\n\n\n\nclas, probs\n\n(tensor(1), tensor([0.3358, 0.6642]))\n\n\nTo get prediction on a new dataframe, you can use the test_dl method of the DataLoaders. That dataframe does not need to have the dependent variable in its column.\n\ntest_ddf = ddf.copy()\ntest_ddf = test_ddf.drop(['salary'], axis=1)\ndl = learn.dls.test_dl(test_ddf)\n\nThen Learner.get_preds will give you the predictions:\n\nlearn.get_preds(dl=dl)\n\n\n\n\n\n\n\n\n(tensor([[0.3358, 0.6642],\n         [0.4716, 0.5284],\n         [0.9259, 0.0741],\n         ...,\n         [0.6240, 0.3760],\n         [0.6896, 0.3104],\n         [0.7852, 0.2148]]),\n None)\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince machine learning models can’t magically understand categories it was never trained on, the data should reflect this. If there are different missing values in your test data you should address this before training\n\n\nExport the learner: Export the content without the items and the optimizer state for inference\n\nlearn.export(\"model.pk\")\n\nWe can then load the exported learner for inference:\n\ntrained_learner = load_learner(\"model.pk\")\ndl = trained_learner.dls.test_dl(test_ddf)\ntrained_learner.get_preds(dl=dl)\n\n\n\n\n\n\n\n\n(tensor([[0.3358, 0.6642],\n         [0.4716, 0.5284],\n         [0.9259, 0.0741],\n         ...,\n         [0.6240, 0.3760],\n         [0.6896, 0.3104],\n         [0.7852, 0.2148]]),\n None)\n\n\nCleanup: delete the exported learner:\n\nif os.path.exists(\"model.pk\"): os.remove(\"model.pk\")",
    "crumbs": [
      "Tutorial: Tabular training with Dask"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BigTabular",
    "section": "",
    "text": "This library replicates much the functionality of the tabular data application in the fastai library to work with larger-than-memory datasets. Pandas, which is used for data transformations in fastai.tabular, is replaced with Dask DataFrames.\nMost of the Dask implementations were written as they were needed for a personal project, but then refactored to match the fastai API more closely. The flow of the Jupyter notebooks follows those from fastai.tabular closely and most of the examples and tests were replicated.",
    "crumbs": [
      "BigTabular"
    ]
  },
  {
    "objectID": "index.html#when-not-to-use-bigtabular",
    "href": "index.html#when-not-to-use-bigtabular",
    "title": "BigTabular",
    "section": "When not to use BigTabular",
    "text": "When not to use BigTabular\nDon’t use this library when you don’t need to use Dask. The Dask website gives the following guidance:\n\nDask DataFrames are often used either when …\n\nYour data is too big\nYour computation is too slow and other techniques don’t work\n\nYou should probably stick to just using pandas if …\n\nYour data is small\nYour computation is fast (subsecond)\nThere are simpler ways to accelerate your computation, like avoiding .apply or Python for loops and using a built-in pandas method instead.",
    "crumbs": [
      "BigTabular"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "BigTabular",
    "section": "Install",
    "text": "Install\npip install bigtabular",
    "crumbs": [
      "BigTabular"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "BigTabular",
    "section": "How to use",
    "text": "How to use\nRefer to the tutorial for a more detailed usage example.\nGet a Dask DataFrame:\n\npath = untar_data(URLs.ADULT_SAMPLE)\nddf = dd.from_pandas(pd.read_csv(path/'adult.csv'))\nddf.head()\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nsalary\n\n\n\n\n0\n49\nPrivate\n101320\nAssoc-acdm\n12.0\nMarried-civ-spouse\n&lt;NA&gt;\nWife\nWhite\nFemale\n0\n1902\n40\nUnited-States\n&gt;=50k\n\n\n1\n44\nPrivate\n236746\nMasters\n14.0\nDivorced\nExec-managerial\nNot-in-family\nWhite\nMale\n10520\n0\n45\nUnited-States\n&gt;=50k\n\n\n2\n38\nPrivate\n96185\nHS-grad\nNaN\nDivorced\n&lt;NA&gt;\nUnmarried\nBlack\nFemale\n0\n0\n32\nUnited-States\n&lt;50k\n\n\n3\n38\nSelf-emp-inc\n112847\nProf-school\n15.0\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nMale\n0\n0\n40\nUnited-States\n&gt;=50k\n\n\n4\n42\nSelf-emp-not-inc\n82297\n7th-8th\nNaN\nMarried-civ-spouse\nOther-service\nWife\nBlack\nFemale\n0\n0\n50\nUnited-States\n&lt;50k\n\n\n\n\n\n\n\nCreate dataloaders. Some of the columns are continuous (like age) and we will treat them as float numbers we can feed our model directly. Others are categorical (like workclass or education) and we will convert them to a unique index that we will feed to embedding layers. We can specify our categorical and continuous column names, as well as the name of the dependent variable in DaskDataLoaders factory methods:\n\ndls = DaskDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [DaskCategorify, DaskFillMissing, DaskNormalize])\n\nCreate a Learner:\n\nlearn = dask_learner(dls, metrics=accuracy)\n\nTrain the model for one epoch:\n\nlearn.fit_one_cycle(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.356636\n0.369994\n0.831705\n00:04\n\n\n\n\n\nWe can then have a look at some predictions:\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\nsalary_pred\n\n\n\n\n0\n5\n13\n1\n5\n2\n5\n1\n0.400453\n0.445578\n1.539163\n1\n1\n\n\n1\n5\n2\n5\n2\n4\n5\n2\n-1.508332\n0.252159\n-0.028897\n0\n0\n\n\n2\n5\n1\n3\n8\n1\n5\n2\n-0.040036\n-0.183701\n-0.028897\n1\n0\n\n\n3\n5\n2\n3\n0\n1\n5\n1\n0.253623\n-1.130087\n-1.204943\n0\n0\n\n\n4\n5\n8\n5\n2\n2\n5\n2\n0.547282\n1.552272\n-0.028897\n0\n0\n\n\n5\n7\n12\n3\n0\n1\n5\n2\n-0.186866\n0.470807\n-0.028897\n0\n0\n\n\n6\n5\n12\n3\n0\n4\n5\n1\n-1.141258\n0.314934\n-0.420913\n0\n0\n\n\n7\n5\n12\n5\n7\n4\n5\n1\n-1.434917\n0.696942\n-0.420913\n0\n0\n\n\n8\n5\n13\n5\n5\n2\n5\n2\n-0.700769\n-0.305753\n-0.028897\n0\n0",
    "crumbs": [
      "BigTabular"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "BigTabular core",
    "section": "",
    "text": "Define Dask versions of the make_date, add_datepart, and add_elapsed_times functions defined in tabular.core. The dask_make_date function uses Dask’s to_datetime function rather than the Pandas version. The dask_add_datepart and dask_add_elapsed_times functions just wrap add_datepart in the Dask map_partitions function.\n\nsource\n\n\n\n dask_make_date (ddf, date_field)\n\nConvert df[date_field] to date type.\n\ndf = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\nddf = dd.from_pandas(df)\ndask_make_date(ddf, 'date')\ntest_eq(ddf['date'].dtype, np.dtype('datetime64[ns]'))\n\n\nsource\n\n\n\n\n dask_add_datepart (ddf, field_name, prefix=None, drop=True, time=False)\n\nHelper function that adds columns relevant to a date in the column field_name of ddf\nFor example if we have a series of dates we can then generate features such as Year, Month, Day, Dayofweek, Is_month_start, etc as shown below:\n\ndf = pd.DataFrame({'date': ['2019-12-04', None, '2019-11-15', '2019-10-24']})\nddf = dd.from_pandas(df)\nddf = dask_add_datepart(ddf, 'date')\nddf.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nWeek\nDay\nDayofweek\nDayofyear\nIs_month_end\nIs_month_start\nIs_quarter_end\nIs_quarter_start\nIs_year_end\nIs_year_start\nElapsed\n\n\n\n\n0\n2019.0\n12.0\n49.0\n4.0\n2.0\n338.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n1.575418e+09\n\n\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nNaN\n\n\n2\n2019.0\n11.0\n46.0\n15.0\n4.0\n319.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n1.573776e+09\n\n\n3\n2019.0\n10.0\n43.0\n24.0\n3.0\n297.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n1.571875e+09\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n dask_add_elapsed_times (ddf, field_names, date_field, base_field)\n\n\ndf = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24'],\n                   'event': [False, True, False, True], 'base': [1,1,2,2]})\nddf = dd.from_pandas(df)\nddf = dask_add_elapsed_times(ddf, ['event'], 'date', 'base')\nddf.head()\n\n\n\n\n\n\n\n\ndate\nevent\nbase\nAfterevent\nBeforeevent\nevent_bw\nevent_fw\n\n\n\n\n0\n2019-12-04\nFalse\n1\n5\n0\n1.0\n0.0\n\n\n1\n2019-11-29\nTrue\n1\n0\n0\n1.0\n1.0\n\n\n2\n2019-11-15\nFalse\n2\n22\n0\n1.0\n0.0\n\n\n3\n2019-10-24\nTrue\n2\n0\n0\n1.0\n1.0\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n dask_cont_cat_split (df, max_card=20, dep_var=None)\n\nHelper function that returns column names of cont and cat variables from given df.\nWe also define a Dask version of the cont_cat_split function. The only difference to the original function is calling compute on the Dask dataframe to determine the cardinality of the columns. This function works by determining if a column is continuous or categorical based on the cardinality of its values. If it is above the max_card parameter (or a float datatype) then it will be added to the cont_names else cat_names. An example is below:\n\n# Example with simple numpy types\ndf = pd.DataFrame({'cat1': [1, 2, 3, 4], 'cont1': [1., 2., 3., 2.], 'cat2': ['a', 'b', 'b', 'a'],\n                   'i8': pd.Series([1, 2, 3, 4], dtype='int8'),\n                   'u8': pd.Series([1, 2, 3, 4], dtype='uint8'),\n                   'f16': pd.Series([1, 2, 3, 4], dtype='float16'),\n                   'y1': [1, 0, 1, 0], 'y2': [2, 1, 1, 0]})\nddf = dd.from_pandas(df)\ncont_names, cat_names = dask_cont_cat_split(ddf)\n\n\n\ncont_names: ['cont1', 'f16']\ncat_names: ['cat1', 'cat2', 'i8', 'u8', 'y1', 'y2']`\n\n\n\n# Example with pandas types and generated columns\ndf = pd.DataFrame({'cat1': pd.Series(['l','xs','xl','s'], dtype='category'),\n                    'ui32': pd.Series([1, 2, 3, 4], dtype='UInt32'),\n                    'i64': pd.Series([1, 2, 3, 4], dtype='Int64'),\n                    'f16': pd.Series([1, 2, 3, 4], dtype='Float64'),\n                    'd1_date': ['2021-02-09', None, '2020-05-12', '2020-08-14'],\n                    })\nddf = dd.from_pandas(df)\nddf = dask_add_datepart(ddf, 'd1_date', drop=False)\n\nddf['cat1'] = ddf['cat1'].cat.set_categories(['xl','l','m','s','xs'], ordered=True)\n\ncont_names, cat_names = dask_cont_cat_split(ddf, max_card=0)\n\n\n\ncont_names: ['ui32', 'i64', 'f16', 'd1_Year', 'd1_Month', 'd1_Week', 'd1_Day', 'd1_Dayofweek', 'd1_Dayofyear', 'd1_Elapsed']\ncat_names: ['cat1', 'd1_date', 'd1_Is_month_end', 'd1_Is_month_start', 'd1_Is_quarter_end', 'd1_Is_quarter_start', 'd1_Is_year_end', 'd1_Is_year_start']\n\n\n\nsource\n\n\n\n\n get_random_train_mask (df, train_frac=0.8, seed=None)\n\n\nsource\n\n\n\n\n RandomTrainMask (train_frac=0.8, seed=None)\n\nInitialize self. See help(type(self)) for accurate signature.\nA class to create a random train/validation set mask over the Dask dataframe.\n\nsource\n\n\n\n\n TabularDask (ddf, procs=None, cat_names=None, cont_names=None,\n              y_names=None, y_block=None, train_mask_func=None,\n              do_setup=True, device=None, reset_index=True)\n\nA Dask DataFrame wrapper that knows which cols are cont/cat/y, and returns rows in __iter__. The aim is to replicate the TabularPandas API as closely as possible.\n\ndf: A DataFrame of your data\ncat_names: Your categorical x variables\ncont_names: Your continuous x variables\ny_names: Your dependent y variables\n\nNote: Mixed y’s such as Regression and Classification is not currently supported, however multiple regression or classification outputs is\n\ny_block: How to sub-categorize the type of y_names (CategoryBlock or RegressionBlock)\ntrain_mask_func: A function that creates a train/validation mask over a DataFrame. See get_random_train_mask for an example.\ndo_setup: A parameter for if Tabular will run the data through the procs upon initialization\ndevice: cuda or cpu",
    "crumbs": [
      "BigTabular core"
    ]
  },
  {
    "objectID": "core.html#initial-preprocessing",
    "href": "core.html#initial-preprocessing",
    "title": "BigTabular core",
    "section": "",
    "text": "Define Dask versions of the make_date, add_datepart, and add_elapsed_times functions defined in tabular.core. The dask_make_date function uses Dask’s to_datetime function rather than the Pandas version. The dask_add_datepart and dask_add_elapsed_times functions just wrap add_datepart in the Dask map_partitions function.\n\nsource\n\n\n\n dask_make_date (ddf, date_field)\n\nConvert df[date_field] to date type.\n\ndf = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\nddf = dd.from_pandas(df)\ndask_make_date(ddf, 'date')\ntest_eq(ddf['date'].dtype, np.dtype('datetime64[ns]'))\n\n\nsource\n\n\n\n\n dask_add_datepart (ddf, field_name, prefix=None, drop=True, time=False)\n\nHelper function that adds columns relevant to a date in the column field_name of ddf\nFor example if we have a series of dates we can then generate features such as Year, Month, Day, Dayofweek, Is_month_start, etc as shown below:\n\ndf = pd.DataFrame({'date': ['2019-12-04', None, '2019-11-15', '2019-10-24']})\nddf = dd.from_pandas(df)\nddf = dask_add_datepart(ddf, 'date')\nddf.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nWeek\nDay\nDayofweek\nDayofyear\nIs_month_end\nIs_month_start\nIs_quarter_end\nIs_quarter_start\nIs_year_end\nIs_year_start\nElapsed\n\n\n\n\n0\n2019.0\n12.0\n49.0\n4.0\n2.0\n338.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n1.575418e+09\n\n\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nNaN\n\n\n2\n2019.0\n11.0\n46.0\n15.0\n4.0\n319.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n1.573776e+09\n\n\n3\n2019.0\n10.0\n43.0\n24.0\n3.0\n297.0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n1.571875e+09\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n dask_add_elapsed_times (ddf, field_names, date_field, base_field)\n\n\ndf = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24'],\n                   'event': [False, True, False, True], 'base': [1,1,2,2]})\nddf = dd.from_pandas(df)\nddf = dask_add_elapsed_times(ddf, ['event'], 'date', 'base')\nddf.head()\n\n\n\n\n\n\n\n\ndate\nevent\nbase\nAfterevent\nBeforeevent\nevent_bw\nevent_fw\n\n\n\n\n0\n2019-12-04\nFalse\n1\n5\n0\n1.0\n0.0\n\n\n1\n2019-11-29\nTrue\n1\n0\n0\n1.0\n1.0\n\n\n2\n2019-11-15\nFalse\n2\n22\n0\n1.0\n0.0\n\n\n3\n2019-10-24\nTrue\n2\n0\n0\n1.0\n1.0\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n dask_cont_cat_split (df, max_card=20, dep_var=None)\n\nHelper function that returns column names of cont and cat variables from given df.\nWe also define a Dask version of the cont_cat_split function. The only difference to the original function is calling compute on the Dask dataframe to determine the cardinality of the columns. This function works by determining if a column is continuous or categorical based on the cardinality of its values. If it is above the max_card parameter (or a float datatype) then it will be added to the cont_names else cat_names. An example is below:\n\n# Example with simple numpy types\ndf = pd.DataFrame({'cat1': [1, 2, 3, 4], 'cont1': [1., 2., 3., 2.], 'cat2': ['a', 'b', 'b', 'a'],\n                   'i8': pd.Series([1, 2, 3, 4], dtype='int8'),\n                   'u8': pd.Series([1, 2, 3, 4], dtype='uint8'),\n                   'f16': pd.Series([1, 2, 3, 4], dtype='float16'),\n                   'y1': [1, 0, 1, 0], 'y2': [2, 1, 1, 0]})\nddf = dd.from_pandas(df)\ncont_names, cat_names = dask_cont_cat_split(ddf)\n\n\n\ncont_names: ['cont1', 'f16']\ncat_names: ['cat1', 'cat2', 'i8', 'u8', 'y1', 'y2']`\n\n\n\n# Example with pandas types and generated columns\ndf = pd.DataFrame({'cat1': pd.Series(['l','xs','xl','s'], dtype='category'),\n                    'ui32': pd.Series([1, 2, 3, 4], dtype='UInt32'),\n                    'i64': pd.Series([1, 2, 3, 4], dtype='Int64'),\n                    'f16': pd.Series([1, 2, 3, 4], dtype='Float64'),\n                    'd1_date': ['2021-02-09', None, '2020-05-12', '2020-08-14'],\n                    })\nddf = dd.from_pandas(df)\nddf = dask_add_datepart(ddf, 'd1_date', drop=False)\n\nddf['cat1'] = ddf['cat1'].cat.set_categories(['xl','l','m','s','xs'], ordered=True)\n\ncont_names, cat_names = dask_cont_cat_split(ddf, max_card=0)\n\n\n\ncont_names: ['ui32', 'i64', 'f16', 'd1_Year', 'd1_Month', 'd1_Week', 'd1_Day', 'd1_Dayofweek', 'd1_Dayofyear', 'd1_Elapsed']\ncat_names: ['cat1', 'd1_date', 'd1_Is_month_end', 'd1_Is_month_start', 'd1_Is_quarter_end', 'd1_Is_quarter_start', 'd1_Is_year_end', 'd1_Is_year_start']\n\n\n\nsource\n\n\n\n\n get_random_train_mask (df, train_frac=0.8, seed=None)\n\n\nsource\n\n\n\n\n RandomTrainMask (train_frac=0.8, seed=None)\n\nInitialize self. See help(type(self)) for accurate signature.\nA class to create a random train/validation set mask over the Dask dataframe.\n\nsource\n\n\n\n\n TabularDask (ddf, procs=None, cat_names=None, cont_names=None,\n              y_names=None, y_block=None, train_mask_func=None,\n              do_setup=True, device=None, reset_index=True)\n\nA Dask DataFrame wrapper that knows which cols are cont/cat/y, and returns rows in __iter__. The aim is to replicate the TabularPandas API as closely as possible.\n\ndf: A DataFrame of your data\ncat_names: Your categorical x variables\ncont_names: Your continuous x variables\ny_names: Your dependent y variables\n\nNote: Mixed y’s such as Regression and Classification is not currently supported, however multiple regression or classification outputs is\n\ny_block: How to sub-categorize the type of y_names (CategoryBlock or RegressionBlock)\ntrain_mask_func: A function that creates a train/validation mask over a DataFrame. See get_random_train_mask for an example.\ndo_setup: A parameter for if Tabular will run the data through the procs upon initialization\ndevice: cuda or cpu",
    "crumbs": [
      "BigTabular core"
    ]
  },
  {
    "objectID": "core.html#transforms",
    "href": "core.html#transforms",
    "title": "BigTabular core",
    "section": "Transforms",
    "text": "Transforms\nThese transforms inherit from TabularProc and are applied as soon as the data is available rather than as data is called from the DataLoader\n\nsource\n\nDaskCategoryMap\n\n DaskCategoryMap (col, sort=True, add_na=False, strict=False)\n\nDask implementation of CategoryMap. Collection of categories with the reverse mapping in o2i\n\nsource\n\n\nDaskCategorify\n\n DaskCategorify (cat_vocabs:\"'dict|None'\"=None)\n\nTransform the categorical variables to something similar to pd.Categorical\nThe Categorify class from fastai.tabular.core.Categorify is modified to: - be compatible with Dask - accept existing vocabs through the cat_vocabs input\nWhile visually in the DataFrame you will not see a change, the classes are stored in to.procs.categorify as we can see below on a dummy DataFrame:\n\nddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,0,2]}))\nto = TabularDask(ddf, DaskCategorify, 'a')\nto.show()\n\n\n\n\n\na\n\n\n\n\n0\n0\n\n\n1\n1\n\n\n2\n2\n\n\n3\n0\n\n\n4\n2\n\n\n\n\n\nEach column’s unique values are stored in a dictionary of column:[values]:\n\ncat = to.procs.dask_categorify\ncat.classes\n\n{'a': ['#na#', 0, 1, 2]}\n\n\nWe can provide an exisiting vocab if it exists, for example if pretrained weights will be used for a categorical variable:\n\nddf = dd.from_pandas(pd.DataFrame({'a':['Cat','Dog','Lion','Leopard','Honey badger']}))\n\nWith default vocab:\n\nto = TabularDask(ddf, DaskCategorify, 'a')\ncat = to.procs.dask_categorify\ncat.classes\n\n{'a': ['#na#', 'Cat', 'Dog', 'Honey badger', 'Leopard', 'Lion']}\n\n\nWith predefined vocab:\n\nvocab = {'a': ['Honey badger', 'Dog', 'Cat', 'Lion','Leopard']}\nto = TabularDask(ddf, DaskCategorify(cat_vocabs=vocab), 'a')\ncat = to.procs.dask_categorify\ncat.classes\n\n{'a': ['Honey badger', 'Dog', 'Cat', 'Lion', 'Leopard']}\n\n\n\nsource\n\n\nDaskNormalize\n\n DaskNormalize (cols=None)\n\nBase class to write a non-lazy tabular processor for dataframes\n\nsource\n\n\nDaskCategorize\n\n DaskCategorize (vocab=None, sort=True, add_na=False)\n\nA transform with a __repr__ that shows its attrs\n\nsource\n\n\nDaskFillStrategy\n\n DaskFillStrategy ()\n\nNamespace containing the various filling strategies.\nCurrently, filling with the median, a constant, and the mode are supported.\n\nsource\n\n\nDaskFillMissing\n\n DaskFillMissing (fill_strategy=&lt;function median&gt;, add_col=True,\n                  fill_vals=None)\n\nFill the missing values in continuous columns.\n\nsource\n\n\nDaskRegressionSetup\n\n DaskRegressionSetup (c=None)\n\nA Dask-compatible transform that floatifies targets\nWe define basic TransformBlocks that are compatible with the Dask transforms:\n\nsource\n\n\nDaskCategoryBlock\n\n DaskCategoryBlock\n                    (vocab:collections.abc.MutableSequence|pandas.core.ser\n                    ies.Series=None, sort:bool=True, add_na:bool=False)\n\nA Dask-compatible TransformBlock for single-label categorical targets\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvocab\nMutableSequence | pd.Series\nNone\nList of unique class names\n\n\nsort\nbool\nTrue\nSort the classes alphabetically\n\n\nadd_na\nbool\nFalse\nAdd #na# to vocab\n\n\n\n\nsource\n\n\nDaskRegressionBlock\n\n DaskRegressionBlock (n_out:int=None)\n\nA Dask-compatible TransformBlock for float targets\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn_out\nint\nNone\nNumber of output values\n\n\n\n\nsource\n\n\nDaskDataLoader\n\n DaskDataLoader (dataset=None, bs=None, num_workers=0, pin_memory=False,\n                 timeout=0, batch_size=None, shuffle=False,\n                 drop_last=False, indexed=None, n=None, device=None,\n                 persistent_workers=False, pin_memory_device='', wif=None,\n                 before_iter=None, after_item=None, before_batch=None,\n                 after_batch=None, after_iter=None, create_batches=None,\n                 create_item=None, create_batch=None, retain=None,\n                 get_idxs=None, sample=None, shuffle_fn=None,\n                 do_batch=None)\n\nIterable dataloader for tabular learning with Dask",
    "crumbs": [
      "BigTabular core"
    ]
  },
  {
    "objectID": "core.html#integration-example",
    "href": "core.html#integration-example",
    "title": "BigTabular core",
    "section": "Integration example",
    "text": "Integration example\nFor a more in-depth explanation, see the BigTabular tutorial\n\npath = untar_data(URLs.ADULT_SAMPLE)\ndf = pd.read_csv(path/'adult.csv')\ndf_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\ndf_test.drop('salary', axis=1, inplace=True)\nddf_main, ddf_test = dd.from_pandas(df_main), dd.from_pandas(df_test)\nddf_main.head()\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nsalary\n\n\n\n\n0\n49\nPrivate\n101320\nAssoc-acdm\n12.0\nMarried-civ-spouse\n&lt;NA&gt;\nWife\nWhite\nFemale\n0\n1902\n40\nUnited-States\n&gt;=50k\n\n\n1\n44\nPrivate\n236746\nMasters\n14.0\nDivorced\nExec-managerial\nNot-in-family\nWhite\nMale\n10520\n0\n45\nUnited-States\n&gt;=50k\n\n\n2\n38\nPrivate\n96185\nHS-grad\nNaN\nDivorced\n&lt;NA&gt;\nUnmarried\nBlack\nFemale\n0\n0\n32\nUnited-States\n&lt;50k\n\n\n3\n38\nSelf-emp-inc\n112847\nProf-school\n15.0\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nMale\n0\n0\n40\nUnited-States\n&gt;=50k\n\n\n4\n42\nSelf-emp-not-inc\n82297\n7th-8th\nNaN\nMarried-civ-spouse\nOther-service\nWife\nBlack\nFemale\n0\n0\n50\nUnited-States\n&lt;50k\n\n\n\n\n\n\n\n\ncat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\ncont_names = ['age', 'fnlwgt', 'education-num']\nprocs = [DaskCategorify, DaskFillMissing, DaskNormalize]\n\n\nto = TabularDask(\n    ddf_main, procs, cat_names, cont_names, y_names=\"salary\", train_mask_func=RandomTrainMask()\n)\n\n\ndls = to.dataloaders()\ndls.valid.show_batch()\n\n/tmp/ipykernel_502869/2346102605.py:128: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\n\n\n\n\n0\nPrivate\nMasters\nDivorced\nExec-managerial\nNot-in-family\nWhite\nFalse\n44.0\n236745.998760\n14.0\n&gt;=50k\n\n\n1\nSelf-emp-inc\nProf-school\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nFalse\n38.0\n112847.001163\n15.0\n&gt;=50k\n\n\n2\nPrivate\nHS-grad\nNever-married\nHandlers-cleaners\nOwn-child\nWhite\nFalse\n20.0\n63210.002966\n9.0\n&lt;50k\n\n\n3\nPrivate\nBachelors\nNever-married\n#na#\nOwn-child\nBlack\nFalse\n23.0\n529222.995495\n13.0\n&lt;50k\n\n\n4\nPrivate\nAssoc-voc\nMarried-civ-spouse\nSales\nHusband\nWhite\nTrue\n43.0\n84660.997258\n10.0\n&lt;50k\n\n\n5\nPrivate\nHS-grad\nMarried-civ-spouse\nCraft-repair\nHusband\nWhite\nFalse\n49.0\n247294.000118\n9.0\n&gt;=50k\n\n\n6\nPrivate\n11th\nMarried-civ-spouse\n#na#\nHusband\nWhite\nFalse\n42.0\n70055.004990\n7.0\n&lt;50k\n\n\n7\nPrivate\nBachelors\nMarried-civ-spouse\nExec-managerial\nHusband\nWhite\nFalse\n45.0\n242390.999669\n13.0\n&gt;=50k\n\n\n8\nPrivate\nSome-college\nNever-married\nSales\nNot-in-family\nBlack\nTrue\n41.0\n140589.998619\n10.0\n&lt;50k\n\n\n\n\n\n\nto.show()\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\n\n\n\n\n0\nPrivate\nAssoc-acdm\nMarried-civ-spouse\n#na#\nWife\nWhite\nFalse\n49.0\n101320.0\n12.0\n&gt;=50k\n\n\n1\nPrivate\nMasters\nDivorced\nExec-managerial\nNot-in-family\nWhite\nFalse\n44.0\n236746.0\n14.0\n&gt;=50k\n\n\n2\nPrivate\nHS-grad\nDivorced\n#na#\nUnmarried\nBlack\nTrue\n38.0\n96185.0\n10.0\n&lt;50k\n\n\n3\nSelf-emp-inc\nProf-school\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nFalse\n38.0\n112847.0\n15.0\n&gt;=50k\n\n\n4\nSelf-emp-not-inc\n7th-8th\nMarried-civ-spouse\nOther-service\nWife\nBlack\nTrue\n42.0\n82297.0\n10.0\n&lt;50k\n\n\n5\nPrivate\nHS-grad\nNever-married\nHandlers-cleaners\nOwn-child\nWhite\nFalse\n20.0\n63210.0\n9.0\n&lt;50k\n\n\n6\nPrivate\nSome-college\nDivorced\n#na#\nOther-relative\nWhite\nFalse\n49.0\n44434.0\n10.0\n&lt;50k\n\n\n7\nPrivate\n11th\nMarried-civ-spouse\n#na#\nHusband\nWhite\nFalse\n37.0\n138940.0\n7.0\n&lt;50k\n\n\n8\nPrivate\nHS-grad\nMarried-civ-spouse\nCraft-repair\nHusband\nWhite\nFalse\n46.0\n328216.0\n9.0\n&gt;=50k\n\n\n9\nSelf-emp-inc\nHS-grad\nMarried-civ-spouse\n#na#\nHusband\nWhite\nTrue\n36.0\n216711.0\n10.0\n&gt;=50k\n\n\n\n\n\nWe can decode any set of transformed data by calling to.decode_row with our raw data:\n\nrow = to.items.head().iloc[0]\nto.decode_row(row)\n\nage                                49.0\nworkclass                       Private\nfnlwgt                    101319.997963\neducation                    Assoc-acdm\neducation-num                      12.0\nmarital-status       Married-civ-spouse\noccupation                         #na#\nrelationship                       Wife\nrace                              White\nsex                              Female\ncapital-gain                          0\ncapital-loss                       1902\nhours-per-week                       40\nnative-country            United-States\nsalary                              NaN\n_int_train_mask                    True\neducation-num_na                  False\nName: 0, dtype: object\n\n\nWe can make new test datasets based on the training data with the to.new()\n\n\n\n\n\n\nNote\n\n\n\nSince machine learning models can’t magically understand categories it was never trained on, the data should reflect this. If there are different missing values in your test data you should address this before training\n\n\n\nto_tst = to.new(ddf_test)\nto_tst.process()\nto_tst.items.head()\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\neducation-num_na\n\n\n\n\n0\n0.467001\n5\n1.320081\n10\n1.174229\n3\n2\n1\n2\nMale\n0\n0\n40\nPhilippines\n1\n\n\n1\n-0.923288\n5\n1.234092\n12\n-0.424305\n3\n15\n1\n4\nMale\n0\n0\n40\nUnited-States\n1\n\n\n2\n1.052386\n5\n0.144505\n2\n-1.223573\n1\n9\n2\n5\nFemale\n0\n0\n37\nUnited-States\n1\n\n\n3\n0.540174\n5\n-0.283457\n12\n-0.424305\n7\n2\n5\n5\nFemale\n0\n0\n43\nUnited-States\n1\n\n\n4\n0.759693\n6\n1.421398\n9\n0.374962\n3\n5\n1\n5\nMale\n0\n0\n60\nUnited-States\n1\n\n\n\n\n\n\n\nWe can then convert it to a DataLoader:\n\ntst_dl = dls.valid.new(to_tst)\ntst_dl.show_batch()\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\n\n\n\n\n0\nPrivate\nBachelors\nMarried-civ-spouse\nAdm-clerical\nHusband\nAsian-Pac-Islander\nFalse\n45.000000\n338104.994720\n13.0\n\n\n1\nPrivate\nHS-grad\nMarried-civ-spouse\nTransport-moving\nHusband\nOther\nFalse\n26.000000\n328663.004174\n9.0\n\n\n2\nPrivate\n11th\nDivorced\nOther-service\nNot-in-family\nWhite\nFalse\n53.000000\n209021.999309\n7.0\n\n\n3\nPrivate\nHS-grad\nWidowed\nAdm-clerical\nUnmarried\nWhite\nFalse\n46.000000\n162030.000870\n9.0\n\n\n4\nSelf-emp-inc\nAssoc-voc\nMarried-civ-spouse\nExec-managerial\nHusband\nWhite\nFalse\n49.000000\n349230.001375\n11.0\n\n\n5\nLocal-gov\nSome-college\nMarried-civ-spouse\nExec-managerial\nHusband\nWhite\nFalse\n34.000000\n124826.998224\n10.0\n\n\n6\nSelf-emp-inc\nSome-college\nMarried-civ-spouse\nSales\nHusband\nWhite\nFalse\n53.000000\n290640.003056\n10.0\n\n\n7\nPrivate\nSome-college\nNever-married\nSales\nOwn-child\nWhite\nFalse\n19.000000\n106273.000912\n10.0\n\n\n8\nPrivate\nSome-college\nMarried-civ-spouse\nProtective-serv\nHusband\nBlack\nFalse\n72.000001\n53684.002983\n10.0",
    "crumbs": [
      "BigTabular core"
    ]
  },
  {
    "objectID": "core.html#other-target-types",
    "href": "core.html#other-target-types",
    "title": "BigTabular core",
    "section": "Other target types",
    "text": "Other target types\n\nMulti-label categories\n\none-hot encoded label\n\ndef _mock_multi_label(df):\n    sal,sex,white = [],[],[]\n    for row in df.itertuples():\n        sal.append(row.salary == '&gt;=50k')\n        sex.append(row.sex == ' Male')\n        white.append(row.race == ' White')\n    df['salary'] = np.array(sal)\n    df['male']   = np.array(sex)\n    df['white']  = np.array(white)\n    return df\n\n\npath = untar_data(URLs.ADULT_SAMPLE)\ndf = pd.read_csv(path/'adult.csv')\ndf_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\ndf_main = _mock_multi_label(df_main)\nddf_main, ddf_test = dd.from_pandas(df_main), dd.from_pandas(df_test)\n\n\nddf_main.head()\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nsalary\nmale\nwhite\n\n\n\n\n0\n49\nPrivate\n101320\nAssoc-acdm\n12.0\nMarried-civ-spouse\n&lt;NA&gt;\nWife\nWhite\nFemale\n0\n1902\n40\nUnited-States\nTrue\nFalse\nTrue\n\n\n1\n44\nPrivate\n236746\nMasters\n14.0\nDivorced\nExec-managerial\nNot-in-family\nWhite\nMale\n10520\n0\n45\nUnited-States\nTrue\nTrue\nTrue\n\n\n2\n38\nPrivate\n96185\nHS-grad\nNaN\nDivorced\n&lt;NA&gt;\nUnmarried\nBlack\nFemale\n0\n0\n32\nUnited-States\nFalse\nFalse\nFalse\n\n\n3\n38\nSelf-emp-inc\n112847\nProf-school\n15.0\nMarried-civ-spouse\nProf-specialty\nHusband\nAsian-Pac-Islander\nMale\n0\n0\n40\nUnited-States\nTrue\nTrue\nFalse\n\n\n4\n42\nSelf-emp-not-inc\n82297\n7th-8th\nNaN\nMarried-civ-spouse\nOther-service\nWife\nBlack\nFemale\n0\n0\n50\nUnited-States\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\ncat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\ncont_names = ['age', 'fnlwgt', 'education-num']\nprocs = [DaskCategorify, DaskFillMissing, DaskNormalize]\ny_names=[\"salary\", \"male\", \"white\"]\n\n\nto = TabularDask(\n    ddf_main, procs, cat_names, cont_names, y_names=y_names, y_block=MultiCategoryBlock(encoded=True, vocab=y_names),\n    train_mask_func=get_random_train_mask\n)\n\nCPU times: user 966 ms, sys: 0 ns, total: 966 ms\nWall time: 1 s\n\n\n\ndls = to.dataloaders()\ndls.valid.show_batch()\n\n/tmp/ipykernel_502869/2346102605.py:128: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\nmale\nwhite\n\n\n\n\n0\nPrivate\nAssoc-acdm\nMarried-civ-spouse\n#na#\nWife\nWhite\nFalse\n49.0\n1.013200e+05\n12.0\nTrue\nFalse\nTrue\n\n\n1\nPrivate\nHS-grad\nMarried-civ-spouse\nCraft-repair\nHusband\nWhite\nFalse\n46.0\n3.282160e+05\n9.0\nTrue\nTrue\nTrue\n\n\n2\nState-gov\nMasters\nDivorced\n#na#\nNot-in-family\nWhite\nFalse\n56.0\n2.741110e+05\n14.0\nFalse\nTrue\nTrue\n\n\n3\nPrivate\nSome-college\nMarried-civ-spouse\n#na#\nWife\nBlack\nTrue\n40.0\n1.889420e+05\n10.0\nFalse\nFalse\nFalse\n\n\n4\nPrivate\nHS-grad\nMarried-spouse-absent\n#na#\nOwn-child\nBlack\nTrue\n29.0\n1.268339e+06\n10.0\nFalse\nTrue\nFalse\n\n\n5\nSelf-emp-not-inc\nSome-college\nDivorced\n#na#\nUnmarried\nWhite\nTrue\n47.0\n2.137450e+05\n10.0\nFalse\nFalse\nTrue\n\n\n6\nPrivate\n11th\nMarried-civ-spouse\n#na#\nHusband\nWhite\nFalse\n42.0\n7.005500e+04\n7.0\nFalse\nTrue\nTrue\n\n\n7\nLocal-gov\nHS-grad\nDivorced\nAdm-clerical\nUnmarried\nWhite\nTrue\n44.0\n1.501710e+05\n10.0\nFalse\nFalse\nTrue\n\n\n8\nPrivate\nMasters\nNever-married\nExec-managerial\nNot-in-family\nWhite\nTrue\n29.0\n1.572620e+05\n10.0\nFalse\nFalse\nTrue\n\n\n\n\n\n\n\n\nRegression\n\npath = untar_data(URLs.ADULT_SAMPLE)\ndf = pd.read_csv(path/'adult.csv')\ndf_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\ndf_main = _mock_multi_label(df_main)\nddf_main, ddf_test = dd.from_pandas(df_main), dd.from_pandas(df_test)\n\n\ncat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\ncont_names = ['fnlwgt', 'education-num']\nprocs = [DaskCategorify, DaskFillMissing, DaskNormalize]\n\n\nto = TabularDask(ddf_main, procs, cat_names, cont_names, y_names='age', train_mask_func=get_random_train_mask)\n\nCPU times: user 860 ms, sys: 7.57 ms, total: 868 ms\nWall time: 871 ms\n\n\n\nto.procs[-1].means\n\nfnlwgt           192459.673567\neducation-num        10.071133\ndtype: float64\n\n\n\ndls = to.dataloaders()\ndls.valid.show_batch()\n\n/tmp/ipykernel_502869/2346102605.py:128: UserWarning: `shuffle` and `drop_last` are currently ignored.\n  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nfnlwgt\neducation-num\nage\n\n\n\n\n0\nPrivate\nBachelors\nMarried-civ-spouse\n#na#\nHusband\nWhite\nTrue\n55291.003489\n10.0\n30.0\n\n\n1\nPrivate\nHS-grad\nNever-married\nHandlers-cleaners\nOwn-child\nBlack\nFalse\n746431.990793\n9.0\n26.0\n\n\n2\nPrivate\nHS-grad\nNever-married\nSales\nOther-relative\nWhite\nFalse\n91524.997303\n9.0\n18.0\n\n\n3\nPrivate\nMasters\nNever-married\nExec-managerial\nNot-in-family\nWhite\nTrue\n157262.001416\n10.0\n29.0\n\n\n4\nPrivate\nHS-grad\nMarried-civ-spouse\n#na#\nHusband\nAmer-Indian-Eskimo\nTrue\n216811.000529\n10.0\n30.0\n\n\n5\nPrivate\nHS-grad\nNever-married\nSales\nOwn-child\nWhite\nTrue\n156084.000249\n10.0\n36.0\n\n\n6\nSelf-emp-not-inc\nDoctorate\nMarried-civ-spouse\n#na#\nHusband\nWhite\nFalse\n65278.004714\n16.0\n32.0\n\n\n7\nLocal-gov\nHS-grad\nNever-married\nAdm-clerical\nOwn-child\nWhite\nFalse\n129232.000243\n9.0\n23.0\n\n\n8\nPrivate\nHS-grad\nMarried-civ-spouse\nTransport-moving\nWife\nWhite\nFalse\n123397.002997\n9.0\n31.0",
    "crumbs": [
      "BigTabular core"
    ]
  }
]