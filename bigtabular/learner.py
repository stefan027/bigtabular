# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_learner.ipynb.

# %% ../nbs/02_learner.ipynb 1
from __future__ import annotations
from fastai.basics import *
from fastai.tabular.core import *
from fastai.tabular.model import *
from fastai.tabular.data import *
from fastai.tabular.learner import *
from .core import *
from .data import *
import dask.dataframe as dd

# %% auto 0
__all__ = ['DaskLearner', 'dask_learner']

# %% ../nbs/02_learner.ipynb 7
class DaskLearner(TabularLearner):
    "`Learner` for tabular data in Dask"
    def get_preds(self,
        ds_idx:int=1, # `DataLoader` to use for predictions if `dl` is None. 0: train. 1: valid
        dl=None, # `DataLoader` to use for predictions, defaults to `ds_idx=1` if None
        with_input:bool=False, # Return inputs with predictions
        with_decoded:bool=False, # Return decoded predictions
        with_loss:bool=False, # Return per item loss with predictions
        act=None, # Apply activation to predictions, defaults to `self.loss_func`'s activation
        inner:bool=False, # If False, create progress bar, show logger, use temporary `cbs`
        cbs:Callback|MutableSequence|None=None, # Temporary `Callback`s to apply during prediction
        **kwargs
    )-> tuple:
        return super().get_preds(
            ds_idx=ds_idx, dl=dl, with_input=with_input, with_decoded=with_decoded, with_loss=with_loss,
            act=act, inner=inner, cbs=cbs, reorder=False, **kwargs
        )

    def show_results(self, ds_idx=1, dl=None, max_n=9, **kwargs):
        return super().show_results(ds_idx=ds_idx, dl=dl, max_n=max_n, shuffle=False, **kwargs)

    def predict(self, 
        row:pd.Series, # Features to be predicted
    ):
        "Predict on a single sample"
        row = row.to_frame().T
        row[list(self.dls.cont_names)] = row[list(self.dls.cont_names)].astype(np.float32)
        dl = self.dls.test_dl(dd.from_pandas(row))
        inp, preds, _, dec_preds = self.get_preds(dl=dl, with_input=True, with_decoded=True)
        df = self.dls.show_batch(inp, max_n=1, show=False)
        full_dec = self.dls.decode(df)
        return full_dec,dec_preds[0],preds[0]

# %% ../nbs/02_learner.ipynb 10
@delegates(TabularLearner.__init__)
def dask_learner(
        dls:DataLoaders,
        layers:list=None, # Size of the layers generated by `LinBnDrop`
        emb_szs:list=None, # Tuples of `n_unique, embedding_size` for all categorical features
        config:dict=None, # Config params for TabularModel from `tabular_config`
        n_out:int=None, # Final output size of the model
        y_range:Tuple=None, # Low and high for the final sigmoid function
        **kwargs
):
    "Get a `Learner` using `dls`, with `metrics`, including a `TabularModel` created using the remaining params."
    if config is None: config = tabular_config()
    if layers is None: layers = [200,100]
    to = dls.train_ds
    emb_szs = get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs)
    if n_out is None: n_out = get_c(dls)
    assert n_out, "`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`"
    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')
    model = TabularModel(emb_szs, len(dls.cont_names), n_out, layers, y_range=y_range, **config)
    return DaskLearner(dls, model, **kwargs)
