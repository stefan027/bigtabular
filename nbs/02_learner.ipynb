{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from fastai.basics import *\n",
    "from fastai.tabular.core import *\n",
    "from fastai.tabular.model import *\n",
    "from fastai.tabular.data import *\n",
    "from fastai.tabular.learner import *\n",
    "from bigtabular.core import *\n",
    "from bigtabular.data import *\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigTabular learner\n",
    "\n",
    "> The function to immediately get a `Learner` ready to train for tabular data with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function you probably want to use in this module is `dask_learner`. It will automatically create a `TabularModel` suitable for your data and infer the right loss function. See the [BigTabular tutorial](tutorial.html) for an example of use in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskLearner(TabularLearner):\n",
    "    \"`Learner` for tabular data in Dask\"\n",
    "    def get_preds(self,\n",
    "        ds_idx:int=1, # `DataLoader` to use for predictions if `dl` is None. 0: train. 1: valid\n",
    "        dl=None, # `DataLoader` to use for predictions, defaults to `ds_idx=1` if None\n",
    "        with_input:bool=False, # Return inputs with predictions\n",
    "        with_decoded:bool=False, # Return decoded predictions\n",
    "        with_loss:bool=False, # Return per item loss with predictions\n",
    "        act=None, # Apply activation to predictions, defaults to `self.loss_func`'s activation\n",
    "        inner:bool=False, # If False, create progress bar, show logger, use temporary `cbs`\n",
    "        cbs:Callback|MutableSequence|None=None, # Temporary `Callback`s to apply during prediction\n",
    "        **kwargs\n",
    "    )-> tuple:\n",
    "        return super().get_preds(\n",
    "            ds_idx=ds_idx, dl=dl, with_input=with_input, with_decoded=with_decoded, with_loss=with_loss,\n",
    "            act=act, inner=inner, cbs=cbs, reorder=False, **kwargs\n",
    "        )\n",
    "\n",
    "    def show_results(self, ds_idx=1, dl=None, max_n=9, **kwargs):\n",
    "        return super().show_results(ds_idx=ds_idx, dl=dl, max_n=max_n, shuffle=False, **kwargs)\n",
    "\n",
    "    def predict(self, \n",
    "        row:pd.Series, # Features to be predicted\n",
    "    ):\n",
    "        \"Predict on a single sample\"\n",
    "        row = row.to_frame().T\n",
    "        row[list(self.dls.cont_names)] = row[list(self.dls.cont_names)].astype(np.float32)\n",
    "        dl = self.dls.test_dl(dd.from_pandas(row))\n",
    "        inp, preds, _, dec_preds = self.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "        df = self.dls.show_batch(inp, max_n=1, show=False)\n",
    "        full_dec = self.dls.decode(df)\n",
    "        return full_dec,dec_preds[0],preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/learner.py#L18){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskLearner\n",
       "\n",
       "\n",
       "\n",
       "*`Learner` for tabular data in Dask*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/learner.py#L18){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskLearner\n",
       "\n",
       "\n",
       "\n",
       "*`Learner` for tabular data in Dask*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DaskLearner, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DaskLearner` inherits from fast.ai's `TabularLearner`. It works exactly as a normal `Learner`, the only difference is that it implements a `predict` method specific to work on a row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@delegates(TabularLearner.__init__)\n",
    "def dask_learner(\n",
    "        dls:DataLoaders,\n",
    "        layers:list=None, # Size of the layers generated by `LinBnDrop`\n",
    "        emb_szs:list=None, # Tuples of `n_unique, embedding_size` for all categorical features\n",
    "        config:dict=None, # Config params for TabularModel from `tabular_config`\n",
    "        n_out:int=None, # Final output size of the model\n",
    "        y_range:Tuple=None, # Low and high for the final sigmoid function\n",
    "        **kwargs\n",
    "):\n",
    "    \"Get a `Learner` using `dls`, with `metrics`, including a `TabularModel` created using the remaining params.\"\n",
    "    if config is None: config = tabular_config()\n",
    "    if layers is None: layers = [200,100]\n",
    "    to = dls.train_ds\n",
    "    emb_szs = get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "    model = TabularModel(emb_szs, len(dls.cont_names), n_out, layers, y_range=y_range, **config)\n",
    "    return DaskLearner(dls, model, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data was built with fastai, you probably won't need to pass anything to `emb_szs` unless you want to change the default of the library (produced by `get_emb_sz`), same for `n_out` which should be automatically inferred. `layers` will default to `[200,100]` and is passed to `TabularModel` along with the `config`.\n",
    "\n",
    "Use `tabular_config` to create a `config` and customize the model used. There is just easy access to `y_range` because this argument is often used.\n",
    "\n",
    "All the other arguments are passed to `Learner`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function gives the same result as ``valid_idx=list(range(800,1000))`` in TabularDataLoaders. This is only the cases for a Dask dataframe with one partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_func(df): return pd.Series([False if i >= 800 and i < 1000 else True for i in range(len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/Insync/OneDrive_personal/Python Workspace/bigtabular/bigtabular/core.py:195: UserWarning: `shuffle` and `drop_last` are currently ignored.\n",
      "  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "ddf = dd.from_pandas(pd.read_csv(path/'adult.csv'))\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [DaskCategorify, DaskFillMissing, DaskNormalize]\n",
    "dls = DaskDataLoaders.from_ddf(ddf, path, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                              y_names=\"salary\", train_mask_func=split_func, bs=64)\n",
    "learn = dask_learner(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/learner.py#L39){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskLearner.predict\n",
       "\n",
       ">      DaskLearner.predict (row:pandas.core.series.Series)\n",
       "\n",
       "*Predict on a single sample*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| row | pd.Series | Features to be predicted |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/learner.py#L39){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskLearner.predict\n",
       "\n",
       ">      DaskLearner.predict (row:pandas.core.series.Series)\n",
       "\n",
       "*Predict on a single sample*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| row | pd.Series | Features to be predicted |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DaskLearner.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass in an individual row of data into our `TabularLearner`'s `predict` method. It's output is slightly different from the other `predict` methods, as this one will always return the input as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row, clas, probs = learn.predict(ddf.head().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>101320.001686</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  workclass    education       marital-status occupation relationship    race  \\\n",
       "0   Private   Assoc-acdm   Married-civ-spouse       #na#         Wife   White   \n",
       "\n",
       "  education-num_na   age         fnlwgt  education-num  \n",
       "0            False  49.0  101320.001686           12.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor([0.4863, 0.5137]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test y_range is passed\n",
    "learn = tabular_learner(dls, y_range=(0,32))\n",
    "assert isinstance(learn.model.layers[-1], SigmoidRange)\n",
    "test_eq(learn.model.layers[-1].low, 0)\n",
    "test_eq(learn.model.layers[-1].high, 32)\n",
    "\n",
    "learn = tabular_learner(dls, config = tabular_config(y_range=(0,32)))\n",
    "assert isinstance(learn.model.layers[-1], SigmoidRange)\n",
    "test_eq(learn.model.layers[-1].low, 0)\n",
    "test_eq(learn.model.layers[-1].high, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
