{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.tabular.all import *\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigTabular core\n",
    "\n",
    "> Basic functions to preprocess larger-than-memory tabular data with Dask before assembling it in `DataLoaders`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Dask versions of the `make_date`, `add_datepart`, and `add_elapsed_times` functions defined in `tabular.core`. The `dask_make_date` function uses Dask's `to_datetime` function rather than the Pandas version. The `dask_add_datepart` and `dask_add_elapsed_times` functions just wrap `add_datepart` in the Dask `map_partitions` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def dask_make_date(ddf, date_field):\n",
    "    \"Convert `df[date_field]` to date type.\"\n",
    "    ddf[date_field] = dd.to_datetime(ddf[date_field], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\n",
    "ddf = dd.from_pandas(df)\n",
    "dask_make_date(ddf, 'date')\n",
    "test_eq(ddf['date'].dtype, np.dtype('datetime64[ns]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def dask_add_datepart(ddf, field_name, prefix=None, drop=True, time=False):\n",
    "    \"Helper function that adds columns relevant to a date in the column field_name of ddf\"\n",
    "    dask_make_date(ddf, field_name)\n",
    "    # return ddf.map_partitions(lambda df: add_datepart(df, field_name, prefix=prefix, drop=drop, time=time))\n",
    "    return ddf.map_partitions(partial(add_datepart, field_name=field_name, prefix=prefix, drop=drop, time=time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example if we have a series of dates we can then generate features such as `Year`, `Month`, `Day`, `Dayofweek`, `Is_month_start`, etc as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.575418e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.573776e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.571875e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  Week   Day  Dayofweek  Dayofyear  Is_month_end  \\\n",
       "0  2019.0   12.0  49.0   4.0        2.0      338.0         False   \n",
       "1     NaN    NaN   NaN   NaN        NaN        NaN         False   \n",
       "2  2019.0   11.0  46.0  15.0        4.0      319.0         False   \n",
       "3  2019.0   10.0  43.0  24.0        3.0      297.0         False   \n",
       "\n",
       "   Is_month_start  Is_quarter_end  Is_quarter_start  Is_year_end  \\\n",
       "0           False           False             False        False   \n",
       "1           False           False             False        False   \n",
       "2           False           False             False        False   \n",
       "3           False           False             False        False   \n",
       "\n",
       "   Is_year_start       Elapsed  \n",
       "0          False  1.575418e+09  \n",
       "1          False           NaN  \n",
       "2          False  1.573776e+09  \n",
       "3          False  1.571875e+09  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'date': ['2019-12-04', None, '2019-11-15', '2019-10-24']})\n",
    "ddf = dd.from_pandas(df)\n",
    "ddf = dask_add_datepart(ddf, 'date')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "test_eq(ddf.columns, ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'])\n",
    "\n",
    "test_eq(ddf[ddf.Elapsed.isna()].compute().shape, (1, 13))\n",
    "\n",
    "# Test that week dtype is consistent with other datepart fields\n",
    "test_eq(ddf['Year'].dtype, ddf['Week'].dtype)\n",
    "\n",
    "test_eq(pd.api.types.is_numeric_dtype(ddf['Elapsed']), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>338</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.575418e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2   f3   f4  Year  Month  Week  Day  Dayofweek  Dayofyear  \\\n",
       "0  1.0  2.0  3.0  4.0  2019     12    49    4          2        338   \n",
       "\n",
       "   Is_month_end  Is_month_start  Is_quarter_end  Is_quarter_start  \\\n",
       "0         False           False           False             False   \n",
       "\n",
       "   Is_year_end  Is_year_start       Elapsed  \n",
       "0        False          False  1.575418e+09  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "df = pd.DataFrame({'f1': [1.],'f2': [2.],'f3': [3.],'f4': [4.],'date':['2019-12-04']})\n",
    "ddf = dd.from_pandas(df)\n",
    "ddf = dask_add_datepart(ddf, 'date')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# Test Order of columns when date isn't in first position\n",
    "test_eq(ddf.columns, ['f1', 'f2', 'f3', 'f4', 'Year', 'Month', 'Week', 'Day',\n",
    "            'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Elapsed'])\n",
    "\n",
    "# Test that week dtype is consistent with other datepart fields\n",
    "test_eq(ddf['Year'].dtype, ddf['Week'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def dask_add_elapsed_times(ddf, field_names, date_field, base_field):\n",
    "    dask_make_date(ddf, date_field)\n",
    "    # return ddf.map_partitions(lambda df: add_elapsed_times(df, field_names, date_field, base_field))\n",
    "    return ddf.map_partitions(partial(add_elapsed_times, field_names=field_names, date_field=date_field, base_field=base_field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>base</th>\n",
       "      <th>Afterevent</th>\n",
       "      <th>Beforeevent</th>\n",
       "      <th>event_bw</th>\n",
       "      <th>event_fw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  event  base  Afterevent  Beforeevent  event_bw  event_fw\n",
       "0 2019-12-04  False     1           5            0       1.0       0.0\n",
       "1 2019-11-29   True     1           0            0       1.0       1.0\n",
       "2 2019-11-15  False     2          22            0       1.0       0.0\n",
       "3 2019-10-24   True     2           0            0       1.0       1.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'date': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24'],\n",
    "                   'event': [False, True, False, True], 'base': [1,1,2,2]})\n",
    "ddf = dd.from_pandas(df)\n",
    "ddf = dask_add_elapsed_times(ddf, ['event'], 'date', 'base')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def dask_cont_cat_split(df, max_card=20, dep_var=None):\n",
    "    \"Helper function that returns column names of cont and cat variables from given `df`.\"\n",
    "    cont_names, cat_names = [], []\n",
    "    for label in df:\n",
    "        if label in L(dep_var): continue\n",
    "        if ((pd.api.types.is_integer_dtype(df[label].dtype) and\n",
    "            # Change for Dask compatibility\n",
    "            df[label].nunique().compute() > max_card) or\n",
    "            pd.api.types.is_float_dtype(df[label].dtype)):\n",
    "            cont_names.append(label)\n",
    "        else: cat_names.append(label)\n",
    "    return cont_names, cat_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a Dask version of the `cont_cat_split` function. The only difference to the original function is calling `compute` on the Dask dataframe to determine the cardinality of the columns. This function works by determining if a column is continuous or categorical based on the cardinality of its values. If it is above the `max_card` parameter (or a `float` datatype) then it will be added to the `cont_names` else `cat_names`. An example is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with simple numpy types\n",
    "df = pd.DataFrame({'cat1': [1, 2, 3, 4], 'cont1': [1., 2., 3., 2.], 'cat2': ['a', 'b', 'b', 'a'],\n",
    "                   'i8': pd.Series([1, 2, 3, 4], dtype='int8'),\n",
    "                   'u8': pd.Series([1, 2, 3, 4], dtype='uint8'),\n",
    "                   'f16': pd.Series([1, 2, 3, 4], dtype='float16'),\n",
    "                   'y1': [1, 0, 1, 0], 'y2': [2, 1, 1, 0]})\n",
    "ddf = dd.from_pandas(df)\n",
    "cont_names, cat_names = dask_cont_cat_split(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_names: ['cont1', 'f16']\n",
      "cat_names: ['cat1', 'cat2', 'i8', 'u8', 'y1', 'y2']`\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "print(f'cont_names: {cont_names}\\ncat_names: {cat_names}`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# Test all columns\n",
    "cont, cat = dask_cont_cat_split(ddf)\n",
    "test_eq((cont, cat), (['cont1', 'f16'], ['cat1', 'cat2', 'i8', 'u8', 'y1', 'y2']))\n",
    "\n",
    "# Test exclusion of dependent variable\n",
    "cont, cat = dask_cont_cat_split(ddf, dep_var='y1')\n",
    "test_eq((cont, cat), (['cont1', 'f16'], ['cat1', 'cat2', 'i8', 'u8', 'y2']))\n",
    "\n",
    "# Test exclusion of multi-label dependent variables\n",
    "cont, cat = dask_cont_cat_split(ddf, dep_var=['y1', 'y2'])\n",
    "test_eq((cont, cat), (['cont1', 'f16'], ['cat1', 'cat2', 'i8', 'u8']))\n",
    "\n",
    "# Test maximal cardinality bound for int variable\n",
    "cont, cat = dask_cont_cat_split(ddf, max_card=3)\n",
    "test_eq((cont, cat), (['cat1', 'cont1', 'i8', 'u8', 'f16'], ['cat2', 'y1', 'y2']))\n",
    "\n",
    "cont, cat = dask_cont_cat_split(ddf, max_card=2)\n",
    "test_eq((cont, cat), (['cat1', 'cont1', 'i8', 'u8', 'f16', 'y2'], ['cat2', 'y1']))\n",
    "\n",
    "cont, cat = dask_cont_cat_split(ddf, max_card=1)\n",
    "test_eq((cont, cat), (['cat1', 'cont1', 'i8', 'u8', 'f16', 'y1', 'y2'], ['cat2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with pandas types and generated columns\n",
    "df = pd.DataFrame({'cat1': pd.Series(['l','xs','xl','s'], dtype='category'),\n",
    "                    'ui32': pd.Series([1, 2, 3, 4], dtype='UInt32'),\n",
    "                    'i64': pd.Series([1, 2, 3, 4], dtype='Int64'),\n",
    "                    'f16': pd.Series([1, 2, 3, 4], dtype='Float64'),\n",
    "                    'd1_date': ['2021-02-09', None, '2020-05-12', '2020-08-14'],\n",
    "                    })\n",
    "ddf = dd.from_pandas(df)\n",
    "ddf = dask_add_datepart(ddf, 'd1_date', drop=False)\n",
    "\n",
    "ddf['cat1'] = ddf['cat1'].cat.set_categories(['xl','l','m','s','xs'], ordered=True)\n",
    "\n",
    "cont_names, cat_names = dask_cont_cat_split(ddf, max_card=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_names: ['ui32', 'i64', 'f16', 'd1_Year', 'd1_Month', 'd1_Week', 'd1_Day', 'd1_Dayofweek', 'd1_Dayofyear', 'd1_Elapsed']\n",
      "cat_names: ['cat1', 'd1_date', 'd1_Is_month_end', 'd1_Is_month_start', 'd1_Is_quarter_end', 'd1_Is_quarter_start', 'd1_Is_year_end', 'd1_Is_year_start']\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "print(f'cont_names: {cont_names}\\ncat_names: {cat_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "cont, cat = dask_cont_cat_split(ddf, max_card=0)\n",
    "test_eq((cont, cat), (\n",
    "    ['ui32', 'i64', 'f16', 'd1_Year', 'd1_Month', 'd1_Week', 'd1_Day', 'd1_Dayofweek', 'd1_Dayofyear', 'd1_Elapsed'],\n",
    "    ['cat1', 'd1_date', 'd1_Is_month_end', 'd1_Is_month_start', 'd1_Is_quarter_end', 'd1_Is_quarter_start', 'd1_Is_year_end', 'd1_Is_year_start']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_random_train_mask(df, train_frac=0.8):\n",
    "    return pd.Series(np.random.random(len(df)) < train_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create a random train/validation set mask over the Dask dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# TODO: align this function with the the tabular.core version\n",
    "class _TabIloc:\n",
    "    \"Get/set rows by iloc and cols by name\"\n",
    "    def __init__(self,to): self.to = to\n",
    "    def __getitem__(self, idxs):\n",
    "        df = self.to.items\n",
    "        if isinstance(idxs,tuple):\n",
    "            rows,cols = idxs\n",
    "            cols = df.columns.isin(cols) if is_listy(cols) else df.columns.get_loc(cols)\n",
    "        else: rows,cols = idxs,slice(None)\n",
    "        return df.iloc[rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TabularDask(CollBase, GetAttr, IterableDataset):\n",
    "    \"\"\"\n",
    "    A Dask `DataFrame` wrapper that knows which cols are cont/cat/y, and returns rows in `__iter__`.\n",
    "    The aim is to replicate the TabularPandas API as closely as possible.\n",
    "    \"\"\"\n",
    "    _default,with_cont='procs',True\n",
    "    def __init__(\n",
    "        self, ddf, procs=None, cat_names=None, cont_names=None, y_names=None, y_block=None, train_mask_func=None,\n",
    "        do_setup=True, device=None, reset_index=True\n",
    "    ):\n",
    "        self.items = ddf.copy()\n",
    "        # if \"_int_train_mask\" not in ddf.columns:\n",
    "        #     if train_mask_func is None:\n",
    "        #         train_mask_func = get_random_train_mask\n",
    "        #     self.items[\"_int_train_mask\"] = ddf.map_partitions(\n",
    "        #         train_mask_func, meta=pd.Series(name=\"_int_train_mask\", dtype=\"bool\")\n",
    "        #     )\n",
    "        if \"_int_train_mask\" not in ddf.columns:\n",
    "            if train_mask_func is None:\n",
    "                self.items[\"_int_train_mask\"] = True\n",
    "            else:\n",
    "                self.items[\"_int_train_mask\"] = ddf.map_partitions(\n",
    "                    train_mask_func, meta=pd.Series(name=\"_int_train_mask\", dtype=\"bool\")\n",
    "                )\n",
    "        if reset_index: ddf = ddf.reset_index(drop=True)\n",
    "        # self._dl_type, self._dbunch_type = DaskDataLoader, DaskDataLoaders\n",
    "        self.y_names, self.device = L(y_names), device\n",
    "\n",
    "        if y_block is None and self.y_names:\n",
    "            # Make ys categorical if they're not numeric\n",
    "            ys = self.items[self.y_names]\n",
    "            if len(ys.select_dtypes(include='number').columns)!=len(ys.columns):\n",
    "                y_block = DaskCategoryBlock()\n",
    "            else:\n",
    "                y_block = DaskRegressionBlock()\n",
    "        if y_block is not None and do_setup:\n",
    "            if callable(y_block): y_block = y_block()\n",
    "            # A bit hacky, but ensuring compatibility with `CategoryBlock` and `RegressionBlock`\n",
    "            # TODO: don't think we need this anymore\n",
    "            if isinstance(y_block.type_tfms[0], Categorize): y_block.type_tfms = DaskCategorize()\n",
    "            elif isinstance(y_block.type_tfms[0], RegressionSetup): y_block.type_tfms = DaskRegressionSetup()\n",
    "            procs = L(procs) + y_block.type_tfms\n",
    "\n",
    "        self.cat_names, self.cont_names, self.procs = L(cat_names), L(cont_names), Pipeline(procs)\n",
    "        self.start, self.end = 0, len(self.items)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def new(self, df):\n",
    "        return type(self)(df, do_setup=False, y_block=TransformBlock(),\n",
    "                          **attrdict(self, 'procs','cat_names','cont_names','y_names', 'device'))\n",
    "        \n",
    "    def subset(self, i):\n",
    "        train = self.items['_int_train_mask']\n",
    "        return self.new(self.items[train if i==0 else ~train])\n",
    "\n",
    "    def copy(self): self.items = self.items.copy(); return self\n",
    "    def decode(self): return self.procs.decode(self)\n",
    "    def decode_row(self, row):\n",
    "        row = row.to_frame().T\n",
    "        row[list(self.cont_names)] = row[list(self.cont_names)].astype(np.float32)\n",
    "        row[list(self.cat_names)] = row[list(self.cat_names)].astype(np.int32)\n",
    "        return self.new(dd.from_pandas(row)).decode().items.compute().iloc[0]\n",
    "\n",
    "    def show(self, max_n=10, **kwargs):\n",
    "        display_df(\n",
    "            self.new(self.all_cols).decode().items.head(max_n).drop(columns=\"_int_train_mask\")\n",
    "        )\n",
    "\n",
    "    def setup(self): self.procs.setup(self)\n",
    "    def process(self): self.procs(self)\n",
    "    def loc(self): return self.items.loc\n",
    "    def iloc(self): return _TabIloc(self)\n",
    "    def targ(self): return self.items[list(self.y_names)]\n",
    "    def x_names (self): return self.cat_names + self.cont_names\n",
    "    def n_subsets(self): return 2\n",
    "    def y(self): return self[self.y_names[0]]\n",
    "    def new_empty(self): raise NotImplementedError\n",
    "    def to_device(self, d=None):\n",
    "        self.device = d\n",
    "        return self\n",
    "\n",
    "    def all_col_names(self):\n",
    "        ys = [n for n in self.y_names if n in self.items.columns]\n",
    "        return self.x_names + self.y_names if len(ys) == len(self.y_names) else self.x_names\n",
    "\n",
    "    def n_inp(self): return int(len(self.cat_names)>0) + int(len(self.cont_names)>0)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        cat_stop = len(self.cat_names)\n",
    "        con_stop = cat_stop + len(self.cont_names)\n",
    "        for i in range(self.items.npartitions):\n",
    "            # df = self.items.get_partition(i).compute()[self.cat_names + self.cont_names + self.y_names]\n",
    "            df = self.items.get_partition(i).compute()[self.all_col_names]\n",
    "            ys = [n for n in self.y_names if n in self.items.columns]\n",
    "            for row in df.itertuples(index=False):\n",
    "                res = (list(row[:cat_stop]), list(row[cat_stop:con_stop]))\n",
    "                if len(ys) == len(self.y_names): res = res + (list(row[con_stop:]),) \n",
    "                # yield (list(cats), list(conts), list(targ))\n",
    "                yield res\n",
    "\n",
    "    def transform(self, cols, f, all_col=True):\n",
    "        if not all_col: cols = [c for c in cols if c in self.items.columns]\n",
    "        if len(cols) > 0:\n",
    "            meta_dtype = \"int16\" if cols[0] in self.cat_names else \"float32\"\n",
    "            meta = pd.DataFrame({c: [] for c in cols}, dtype=meta_dtype)\n",
    "            self[cols] = self[cols].map_partitions(lambda df: df.transform(f), meta=meta)\n",
    "\n",
    "    def dataloaders(self, \n",
    "        bs:int=64, # Batch size\n",
    "        shuffle_train:bool=None, # (Deprecated, use `shuffle`) Shuffle training `DataLoader`\n",
    "        shuffle:bool=True, # Shuffle is currently ignored in `DaskDataLoader`\n",
    "        val_shuffle:bool=False, # Shuffle validation `DataLoader`\n",
    "        n:int=None, # Size of `Datasets` used to create `DataLoader`\n",
    "        path:str|Path='.', # Path to put in `DataLoaders`\n",
    "        dl_type:DataLoader=None, # Type of `DataLoader`\n",
    "        dl_kwargs:list=None, # List of kwargs to pass to individual `DataLoader`s\n",
    "        device:torch.device=None, # Device to put `DataLoaders`\n",
    "        drop_last:bool=None, # Drop last incomplete batch, defaults to `shuffle`. Currently ignored in `DaskDataLoader`\n",
    "        val_bs:int=None, # Validation batch size, defaults to `bs`\n",
    "        **kwargs\n",
    "    ) -> DataLoaders:\n",
    "        if shuffle_train is not None:\n",
    "            shuffle=shuffle_train\n",
    "            warnings.warn('`shuffle_train` is deprecated. Use `shuffle` instead.',DeprecationWarning)\n",
    "        if device is None: device=default_device()\n",
    "        if dl_kwargs is None: dl_kwargs = [{}] * self.n_subsets\n",
    "        if dl_type is None: dl_type = self._dl_type\n",
    "        # if drop_last is None: drop_last = shuffle\n",
    "        if shuffle or drop_last:\n",
    "            shuffle, drop_last = False, False\n",
    "            warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n",
    "        val_kwargs={k[4:]:v for k,v in kwargs.items() if k.startswith('val_')}\n",
    "        def_kwargs = {'bs':bs,'shuffle':shuffle,'drop_last':drop_last,'n':n,'device':device}\n",
    "        dl = dl_type(self.subset(0), **merge(kwargs,def_kwargs, dl_kwargs[0]))\n",
    "        def_kwargs = {'bs':bs if val_bs is None else val_bs,'shuffle':val_shuffle,'n':None,'drop_last':False}\n",
    "        dls = [dl] + [dl.new(self.subset(i), **merge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n",
    "                      for i in range(1, self.n_subsets)]\n",
    "        return self._dbunch_type(*dls, path=path, device=device)\n",
    "\n",
    "properties(TabularDask,'iloc','targ','all_col_names','n_subsets','x_names','y', 'n_inp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `df`: A `DataFrame` of your data\n",
    "* `cat_names`: Your categorical `x` variables\n",
    "* `cont_names`: Your continuous `x` variables\n",
    "* `y_names`: Your dependent `y` variables\n",
    "  * Note: Mixed y's such as Regression and Classification is not currently supported, however multiple regression or classification outputs is\n",
    "* `y_block`: How to sub-categorize the type of `y_names` (`CategoryBlock` or `RegressionBlock`)\n",
    "* `train_mask_func`: A function that creates a train/validation mask over a `DataFrame`. See `get_random_train_mask` for an example.\n",
    "* `do_setup`: A parameter for if `Tabular` will run the data through the `procs` upon initialization\n",
    "* `device`: `cuda` or `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _add_prop(cls, nm):\n",
    "    @property\n",
    "    def f(o): return o[list(getattr(o,nm+'_names'))]\n",
    "    @f.setter\n",
    "    def fset(o, v): o[getattr(o,nm+'_names')] = v\n",
    "    setattr(cls, nm+'s', f)\n",
    "    setattr(cls, nm+'s', fset)\n",
    "\n",
    "_add_prop(TabularDask, 'cat')\n",
    "_add_prop(TabularDask, 'cont')\n",
    "_add_prop(TabularDask, 'y')\n",
    "_add_prop(TabularDask, 'x')\n",
    "_add_prop(TabularDask, 'all_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "TabularDask.train, TabularDask.valid = add_props(lambda i,x: x.subset(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "df = pd.DataFrame({'a':[0,1,2,0,2], 'b':[0,0,0,0,1]})\n",
    "ddf = dd.from_pandas(df)\n",
    "to = TabularDask(ddf, cat_names='a')\n",
    "t = pickle.loads(pickle.dumps(to))\n",
    "test_eq(t.items,to.items)\n",
    "test_eq(to.all_cols,to[['a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/bigtabular/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:359: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "def _count_objs(o):\n",
    "    \"Counts number of instanes of class `o`\"\n",
    "    objs = gc.get_objects()\n",
    "    return len([x for x in objs if isinstance(x, pd.DataFrame)])\n",
    "\n",
    "df = pd.DataFrame({'a':[0,1,2,0,2], 'b':[0,0,0,0,1]})\n",
    "df_b = pd.DataFrame({'a':[1,2,0,0,2], 'b':[1,0,3,0,1]})\n",
    "ddf, ddf_b = dd.from_pandas(df), dd.from_pandas(df_b)\n",
    "\n",
    "to = TabularPandas(df, cat_names='a', inplace=True)\n",
    "\n",
    "_init_count = _count_objs(dd.DataFrame)\n",
    "to_new = to.new(df_b, inplace=True)\n",
    "test_eq(_init_count, _count_objs(dd.DataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These transforms inherit from `TabularProc` and are applied as soon as the data is available rather than as data is called from the `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskCategoryMap(CategoryMap):\n",
    "    \"Dask implementation of CategoryMap. Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False, strict=False):\n",
    "        if hasattr(col, 'dtype') and isinstance(col.dtype, CategoricalDtype):\n",
    "            items = L(col.cat.categories, use_list=True)\n",
    "            #Remove non-used categories while keeping order\n",
    "            if strict: items = L(o for o in items if o in col.unique())\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = col.unique()\n",
    "            # Dask compatibility\n",
    "            if hasattr(items, \"compute\"):\n",
    "                items = items.compute()\n",
    "                # Dask sometimes (always?) represents NANs as `pandas._libs.missing.NAType` values \n",
    "                # which do not work with the `o==o` condition (TypeError: boolean value of NA is ambiguous)\n",
    "                items = items.dropna()\n",
    "            items = L(o for o in items if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#5) [1,2,3,7,9], {1: 0, 2: 1, 3: 2, 7: 3, 9: 4})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategoryMap(pd.Series([9,1,2,7,3,7,1,9]))\n",
    "a.items, a.o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#5) [9,1,2,7,3], {9: 0, 1: 1, 2: 2, 7: 3, 3: 4})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategoryMap(pd.Series([9,1,2,7,3,7,1,9]), sort=False)\n",
    "a.items, a.o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#5) [9,1,2,7,3], {9: 0, 1: 1, 2: 2, 7: 3, 3: 4})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategoryMap([9,1,2,7,3,7,1,9], sort=False)\n",
    "a.items, a.o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#5) [9,1,2,7,3], {9: 0, 1: 1, 2: 2, 7: 3, 3: 4})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategoryMap(dd.from_pandas(pd.Series([9,1,2,7,3,7,1,9])), sort=False)\n",
    "a.items, a.o2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskCategorify(TabularProc):\n",
    "    \"Transform the categorical variables to something similar to `pd.Categorical`\"\n",
    "    order = 1\n",
    "    def __init__(self, cat_vocabs:'dict | None'=None):\n",
    "        classes = {}\n",
    "        if cat_vocabs is not None:\n",
    "            classes = {n: DaskCategoryMap(vocab, sort=False, add_na=False) for n, vocab in cat_vocabs.items()}\n",
    "        store_attr(classes=classes, but='to')\n",
    "\n",
    "    def setups(self, to):\n",
    "        _cat_names = [n for n in to.cat_names if n not in self.classes]\n",
    "        # Convert numeric categorical columns to strings\n",
    "        _num_cats = list(to.items[_cat_names].select_dtypes(include=['number', 'bool']).columns)\n",
    "        to.items[_num_cats] = to.items[_num_cats].astype('category')\n",
    "        _cats = getattr(to, 'train', to).items[_cat_names].categorize()\n",
    "        for n in _cat_names:\n",
    "            self.classes[n] = DaskCategoryMap(_cats[n], add_na=(n in to.cat_names))\n",
    "\n",
    "    def encodes(self, to): to.transform(list(self.classes.keys()), partial(_apply_cats, voc=self.classes, add=1))\n",
    "    def decodes(self, to): to.transform(list(self.classes.keys()), partial(_decode_cats, voc=self.classes))\n",
    "    def __getitem__(self,k): return self.classes[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [9, 1, 2, 7, 3]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategorify({'a': pd.Series([9,1,2,7,3,7,1,9])})\n",
    "a.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [9, 1, 2, 7, 3]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategorify({'a': [9,1,2,7,3,7,1,9]})\n",
    "a.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [9, 1, 2, 7, 3]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategorify({'a': dd.from_pandas(pd.Series([9,1,2,7,3,7,1,9]))})\n",
    "a.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [9, 1, 2, 7, 3], 'b': [0, 1, 2]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "a = DaskCategorify({'a': [9,1,2,7,3,7,1,9], 'b': [0,1,2]})\n",
    "a.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _apply_cats (c, voc, add):\n",
    "    if not (hasattr(c, 'dtype') and isinstance(c.dtype, CategoricalDtype)):\n",
    "        return pd.Categorical(c, categories=voc[c.name][add:]).codes+add\n",
    "    return c.cat.codes+add #if is_categorical_dtype(c) else c.map(voc[c.name].o2i)\n",
    "def _decode_cats(c, voc): return c.map(dict(enumerate(voc[c.name].items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/core.py#L248){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskCategorify\n",
       "\n",
       ">      DaskCategorify (cat_vocabs:\"'dict|None'\"=None)\n",
       "\n",
       "*Transform the categorical variables to something similar to `pd.Categorical`*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/core.py#L248){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskCategorify\n",
       "\n",
       ">      DaskCategorify (cat_vocabs:\"'dict|None'\"=None)\n",
       "\n",
       "*Transform the categorical variables to something similar to `pd.Categorical`*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DaskCategorify, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Categorify` class from `fastai.tabular.core.Categorify` is modified to:\n",
    "  - be compatible with Dask\n",
    "  - accept existing vocabs through the `cat_vocabs` input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While visually in the `DataFrame` you will not see a change, the classes are stored in `to.procs.categorify` as we can see below on a dummy `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,0,2]}))\n",
    "to = TabularDask(ddf, DaskCategorify, 'a')\n",
    "to.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column's unique values are stored in a dictionary of `column:[values]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['#na#', 0, 1, 2]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = to.procs.dask_categorify\n",
    "cat.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "def test_series(a,b): return test_eq(list(a), b)\n",
    "test_series(cat['a'], ['#na#',0,1,2])\n",
    "test_series(to['a'], [1,2,3,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "ddf1 = dd.from_pandas(pd.DataFrame({'a':[1,0,3,-1,2]}))\n",
    "to1 = to.new(ddf1)\n",
    "to1.process()\n",
    "#Values that weren't in the training df are sent to 0 (na)\n",
    "test_series(to1['a'], [2,1,0,0,3])\n",
    "to2 = cat.decode(to1)\n",
    "test_series(to2['a'], [1,0,'#na#','#na#',2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can provide an exisiting vocab if it exists, for example if pretrained weights will be used for a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.from_pandas(pd.DataFrame({'a':['Cat','Dog','Lion','Leopard','Honey badger']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['#na#', 'Cat', 'Dog', 'Honey badger', 'Leopard', 'Lion']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to = TabularDask(ddf, DaskCategorify, 'a')\n",
    "cat = to.procs.dask_categorify\n",
    "cat.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With predefined vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['Honey badger', 'Dog', 'Cat', 'Lion', 'Leopard']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {'a': ['Honey badger', 'Dog', 'Cat', 'Lion','Leopard']}\n",
    "to = TabularDask(ddf, DaskCategorify(cat_vocabs=vocab), 'a')\n",
    "cat = to.procs.dask_categorify\n",
    "cat.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test with splits\n",
    "cat = DaskCategorify()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,2]}))\n",
    "to = TabularDask(ddf, cat, 'a', train_mask_func=lambda df: df['a'] <=2)\n",
    "test_series(cat['a'], ['#na#',0,1,2])\n",
    "test_series(to['a'], [1,2,3,0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True)}))\n",
    "to = TabularDask(ddf, DaskCategorify, 'a')\n",
    "cat = to.procs.dask_categorify\n",
    "test_series(cat['a'], ['#na#','H','M','L'])\n",
    "test_series(to.items.a, [2,1,3,2])\n",
    "to2 = cat.decode(to)\n",
    "test_series(to2['a'], ['M','H','L','M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskNormalize(TabularProc):\n",
    "    parameters,order = L('mean', 'std'),99\n",
    "    def __init__(self, cols=None):\n",
    "        self.cols = listify(cols)\n",
    "\n",
    "    def setups(self, to):\n",
    "        if not self.cols: self.cols = listify(to.cont_names)\n",
    "        # store_attr(but='to', means=getattr(to, 'train', to).conts.mean().compute(),\n",
    "        #            stds=getattr(to, 'train', to).conts.std(ddof=0).compute()+1e-7)\n",
    "        store_attr(but='to', means=getattr(to, 'train', to).items[self.cols].mean().compute(),\n",
    "                   stds=getattr(to, 'train', to).items[self.cols].std(ddof=0).compute())\n",
    "        return self(to)\n",
    "\n",
    "    def encodes(self, to):\n",
    "        # to.conts = to.conts.map_partitions(lambda df: (df-self.means) / self.stds)\n",
    "        to.items[self.cols] = to.items[self.cols].map_partitions(lambda df: (df-self.means) / self.stds)\n",
    "        return to\n",
    "\n",
    "    def decodes(self, to):\n",
    "        # to.conts = to.conts.map_partitions(lambda df: (df*self.stds) + self.means)\n",
    "        to.items[self.cols] = to.items[self.cols].map_partitions(lambda df: (df*self.stds) + self.means)\n",
    "        return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskCategorize(DisplayedTransform):\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, sort=True, add_na=False):\n",
    "        self.vocab = vocab\n",
    "        if vocab is not None: self.vocab = DaskCategoryMap(vocab, sort=sort, add_na=add_na)\n",
    "\n",
    "    def setups(self, to):\n",
    "        if len(to.y_names) > 0:\n",
    "            if self.vocab is None:\n",
    "                self.vocab = DaskCategoryMap(getattr(to, 'train', to).iloc[:,to.y_names[0]], strict=True)\n",
    "            else:\n",
    "                self.vocab = DaskCategoryMap(self.vocab, sort=False, add_na=self.add_na)\n",
    "            self.c = len(self.vocab)\n",
    "        return self(to)\n",
    "\n",
    "    def encodes(self, to):\n",
    "        to.transform(to.y_names, partial(_apply_cats, voc={n: self.vocab for n in to.y_names}, add=0), all_col=False)\n",
    "        return to\n",
    "\n",
    "    def decodes(self, to):\n",
    "        to.transform(to.y_names, partial(_decode_cats, voc={n: self.vocab for n in to.y_names}), all_col=False)\n",
    "        return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskFillStrategy:\n",
    "    \"Namespace containing the various filling strategies.\"\n",
    "    def median  (c,fill): return c.median_approximate().compute()\n",
    "    # def constant(c,fill): return fill\n",
    "    def constant(c,fill): return {n: fill[n] for n in c.columns}\n",
    "    # def mode    (c,fill): return c.dropna().value_counts().idxmax().compute()\n",
    "    def mode    (c,fill): return {n: c[n].dropna().value_counts().idxmax().compute() for n in c.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, filling with the `median`, a `constant`, and the `mode` are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskFillMissing(TabularProc):\n",
    "    \"Fill the missing values in continuous columns.\"\n",
    "    def __init__(self, fill_strategy=DaskFillStrategy.median, add_col=True, fill_vals=None):\n",
    "        if fill_vals is None: fill_vals = defaultdict(int)\n",
    "        store_attr()\n",
    "\n",
    "    def setups(self, to):\n",
    "        missing = to.conts.isnull().any().compute()\n",
    "        missing_cols = list(missing[missing].keys())\n",
    "        # store_attr(but='to', na_dict={n:self.fill_strategy(to[n], self.fill_vals[n])\n",
    "        #                     for n in missing[missing].keys()})\n",
    "        store_attr(but='to', na_dict=dict(self.fill_strategy(to[missing_cols], self.fill_vals)))\n",
    "        self.fill_strategy = self.fill_strategy.__name__\n",
    "\n",
    "    def encodes(self, to):\n",
    "        missing = to.conts.isnull()\n",
    "        missing_any = missing.any().compute()\n",
    "        for n in missing_any[missing_any].keys():\n",
    "            assert n in self.na_dict, f\"nan values in `{n}` but not in setup training set\"\n",
    "        if self.na_dict:\n",
    "            to.items = to.items.fillna(self.na_dict)\n",
    "            if self.add_col:\n",
    "                for n in self.na_dict.keys():\n",
    "                    to.items[n+'_na'] = missing[n]\n",
    "                    if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/core.py#L335){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskFillMissing\n",
       "\n",
       ">      DaskFillMissing (fill_strategy=<function median>, add_col=True,\n",
       ">                       fill_vals=None)\n",
       "\n",
       "*Fill the missing values in continuous columns.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/stefan027/bigtabular/blob/main/bigtabular/core.py#L335){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DaskFillMissing\n",
       "\n",
       ">      DaskFillMissing (fill_strategy=<function median>, add_col=True,\n",
       ">                       fill_vals=None)\n",
       "\n",
       "*Fill the missing values in continuous columns.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DaskFillMissing, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskRegressionSetup(DisplayedTransform):\n",
    "    \"A Dask-compatible transform that floatifies targets\"\n",
    "    loss_func=MSELossFlat()\n",
    "    def __init__(self, c=None): store_attr()\n",
    "\n",
    "    def setups(self, to):\n",
    "        if self.c is not None: return\n",
    "        self.c = len(to.y_names)\n",
    "        return self(to)\n",
    "\n",
    "    def encodes(self, to):\n",
    "        for c in to.y_names:\n",
    "            if c in to.items.columns: to[c] = to[c].astype(\"float\")\n",
    "        return to\n",
    "    def decodes(self, to): return to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define basic `TransformBlock`s that are compatible with the Dask transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DaskCategoryBlock(\n",
    "    vocab:MutableSequence|pd.Series=None, # List of unique class names\n",
    "    sort:bool=True, # Sort the classes alphabetically\n",
    "    add_na:bool=False, # Add `#na#` to `vocab`\n",
    "):\n",
    "    \"A Dask-compatible `TransformBlock` for single-label categorical targets\"\n",
    "    return TransformBlock(type_tfms=DaskCategorize(vocab=vocab, sort=sort, add_na=add_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def DaskRegressionBlock(\n",
    "    n_out:int=None, # Number of output values\n",
    "):\n",
    "    \"A Dask-compatible `TransformBlock` for float targets\"\n",
    "    return TransformBlock(type_tfms=DaskRegressionSetup(c=n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test with targets\n",
    "cat = DaskCategorify()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,2], 'b': ['a', 'b', 'a', 'b', 'b']}))\n",
    "def split_func(df): return df['a'] <=2\n",
    "to = TabularDask(ddf, cat, 'a', train_mask_func=split_func, y_names='b')\n",
    "test_series(to.vocab, ['a', 'b'])\n",
    "test_series(to['b'], [0,1,0,1,1])\n",
    "to2 = to.procs.decode(to)\n",
    "test_series(to2['b'], ['a', 'b', 'a', 'b', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "cat = DaskCategorify()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,2], 'b': ['a', 'b', 'a', 'b', 'b']}))\n",
    "def split_func(df): return df['a'] <=2\n",
    "to = TabularDask(ddf, cat, 'a', train_mask_func=split_func, y_names='b')\n",
    "test_series(to.vocab, ['a', 'b'])\n",
    "test_series(to['b'], [0,1,0,1,1])\n",
    "to2 = to.procs.decode(to)\n",
    "test_series(to2['b'], ['a', 'b', 'a', 'b', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test with targets and train\n",
    "cat = DaskCategorify()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,2], 'b': ['a', 'b', 'a', 'c', 'b']}))\n",
    "def split_func(df): return df['a'] <=2\n",
    "to = TabularDask(ddf, cat, 'a', train_mask_func=split_func, y_names='b')\n",
    "test_series(to.vocab, ['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#test to ensure no copies of the dataframe are stored\n",
    "cat = DaskCategorify()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "def split_func(df): return df['a'] <=2\n",
    "to = TabularDask(ddf, cat, cont_names='a', train_mask_func=split_func)\n",
    "test_eq(hasattr(to.procs.dask_categorify, 'to'), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "norm = DaskNormalize()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "to = TabularDask(ddf, norm, cont_names='a')\n",
    "x = np.array([0,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means['a'], m)\n",
    "test_close(norm.stds['a'], s)\n",
    "test_close(to['a'].compute().values, (x-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "ddf1 = dd.from_pandas(pd.DataFrame({'a':[5,6,7]}))\n",
    "to1 = to.new(ddf1)\n",
    "to1.process()\n",
    "test_close(to1['a'].compute().values, (np.array([5,6,7])-m)/s)\n",
    "to2 = norm.decode(to1)\n",
    "test_close(to2['a'].compute().values, [5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "norm = DaskNormalize()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "to = TabularDask(ddf, norm, cont_names='a', train_mask_func=lambda df: df['a'] <=2)\n",
    "x = np.array([0,1,2])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means['a'], m)\n",
    "test_close(norm.stds['a'], s)\n",
    "test_close(to['a'].compute().values, (np.array([0,1,2,3,4])-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "norm = DaskNormalize()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "to = TabularDask(ddf, norm, cont_names='a', train_mask_func=lambda df: df['a'] <=2)\n",
    "test_eq(hasattr(to.procs.dask_normalize, 'to'), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "fill1,fill2,fill3 = (DaskFillMissing(fill_strategy=s)\n",
    "                     for s in [DaskFillStrategy.median, DaskFillStrategy.constant, DaskFillStrategy.mode])\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,np.nan,1,2,3,4]}))\n",
    "ddf1 = ddf.copy(); ddf2 = ddf.copy()\n",
    "tos = (TabularDask(ddf, fill1, cont_names='a'),\n",
    "       TabularDask(ddf1, fill2, cont_names='a'),\n",
    "       TabularDask(ddf2, fill3, cont_names='a'))\n",
    "test_eq(fill1.na_dict, {'a': 1.5})\n",
    "test_eq(fill2.na_dict, {'a': 0})\n",
    "test_eq(fill3.na_dict, {'a': 1.0})\n",
    "\n",
    "for t in tos: test_eq(t.cat_names, ['a_na'])\n",
    "\n",
    "for to_,v in zip(tos, [1.5, 0., 1.]):\n",
    "    test_eq(to_.items.compute()['a'].values, np.array([0, 1, v, 1, 2, 3, 4]))\n",
    "    test_eq(to_.items.compute()['a_na'].values, np.array([0, 0, 1, 0, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "fill = DaskFillMissing()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,np.nan,1,2,3,4], 'b': [0,1,2,3,4,5,6]}))\n",
    "to = TabularDask(ddf, fill, cont_names=['a', 'b'])\n",
    "test_eq(fill.na_dict, {'a': 1.5})\n",
    "test_eq(to.cat_names, ['a_na'])\n",
    "\n",
    "test_eq(to.items.compute()['a'].values, np.array([0, 1, 1.5, 1, 2, 3, 4]))\n",
    "test_eq(to.items.compute()['a_na'].values, np.array([0, 0, 1, 0, 0, 0, 0]))\n",
    "test_eq(to.items.compute()['b'].values, np.array([0,1,2,3,4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "fill = DaskFillMissing()\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,np.nan,1,2,3,4], 'b': [0,1,2,3,4,5,6]}))\n",
    "to = TabularDask(ddf, fill, cont_names=['a', 'b'])\n",
    "test_eq(hasattr(to.procs.dask_fill_missing, 'to'), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularDask Pipelines -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "procs = [DaskNormalize, DaskCategorify, DaskFillMissing, noop]\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4]}))\n",
    "to = TabularDask(ddf, procs, cat_names='a', cont_names='b')\n",
    "\n",
    "#Test setup and apply on df_main\n",
    "test_series(to.cat_names, ['a', 'b_na'])\n",
    "test_series(to.items.compute()['a'], [1,2,3,2,2,3,1])\n",
    "test_series(to.items.compute()['b_na'], [1,1,2,1,1,1,1])\n",
    "x = np.array([0,1,1.5,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(to.items.compute()['b'].values, (x-m)/s)\n",
    "test_eq(to.classes, {'a': ['#na#',0,1,2], 'b_na': ['#na#',False,True]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#Test apply on y_names\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']}))\n",
    "to = TabularDask(ddf, procs, 'a', 'b', y_names='c')\n",
    "\n",
    "test_series(to.cat_names, ['a', 'b_na'])\n",
    "test_series(to.items.compute()['a'], [1,2,3,2,2,3,1])\n",
    "test_series(to.items.compute()['b_na'], [1,1,2,1,1,1,1])\n",
    "test_series(to.items.compute()['c'], [1,0,1,0,0,1,0])\n",
    "x = np.array([0,1,1.5,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(to.items.compute()['b'].values, (x-m)/s)\n",
    "test_eq(to.classes, {'a': ['#na#',0,1,2], 'b_na': ['#na#',False,True]})\n",
    "test_eq(to.vocab, ['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']}))\n",
    "to = TabularDask(ddf, procs, 'a', 'b', y_names='c')\n",
    "\n",
    "test_series(to.cat_names, ['a', 'b_na'])\n",
    "test_series(to.items.compute()['a'], [1,2,3,2,2,3,1])\n",
    "test_eq(ddf.a.dtype, np.int64 if sys.platform == \"win32\" else int)\n",
    "test_series(to.items.compute()['b_na'], [1,1,2,1,1,1,1])\n",
    "test_series(to.items.compute()['c'], [1,0,1,0,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "ddf = dd.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,np.nan,1,1,2,3,4], 'c': ['b','a','b','a','a','b','a']}))\n",
    "def split_func(df): return pd.Series([True, True, False, False, True, False, True])\n",
    "to = TabularDask(ddf, procs, cat_names='a', cont_names='b', y_names='c', train_mask_func=split_func)\n",
    "\n",
    "test_series(to.cat_names, ['a', 'b_na'])\n",
    "test_series(to.train.items.compute()['a'], [1,2,2,1])\n",
    "test_eq(ddf.a.dtype, np.int64 if sys.platform == \"win32\" else int)\n",
    "test_series(to.train.items.compute()['b_na'], [1,2,1,1])\n",
    "test_series(to.train.items.compute()['c'], [1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DaskDataLoader(DataLoader):\n",
    "    \"Iterable dataloader for tabular learning with Dask\"\n",
    "    # TODO: align with TabDataLoader + ReadTabBatch (fastai.tabular.core)?\n",
    "    def create_batch(self, b):\n",
    "        b = list(map(np.array, zip(*b)))\n",
    "        cats, conts = tensor(b[0]).long(), tensor(b[1]).float()\n",
    "        res = (cats, conts)\n",
    "        # add target if available\n",
    "        if len(b) > 2: res = res + (tensor(b[2]),)\n",
    "        return res\n",
    "\n",
    "    def decode(self, b):\n",
    "        tmp = self.dataset.new(dd.from_pandas(b))\n",
    "        return tmp.decode().items.compute().drop(columns=\"_int_train_mask\")\n",
    "\n",
    "    def show_batch(self,\n",
    "        b=None, # Batch to show\n",
    "        max_n:int=9, # Maximum number of items to show,\n",
    "        show:bool=True, # Whether to display data\n",
    "    ):\n",
    "        \"Show `max_n` input(s) and target(s) from the batch.\"\n",
    "        if b is None: b = self.one_batch()\n",
    "        x1 = pd.DataFrame(b[0][:max_n].cpu().numpy(), columns=self.dataset.cat_names)\n",
    "        x2 = pd.DataFrame(b[1][:max_n].cpu().numpy(), columns=self.dataset.cont_names)\n",
    "        b_ = [x1, x2]\n",
    "        if len(b) > 2:\n",
    "            y = pd.DataFrame(b[2][:max_n].cpu().numpy(), columns=self.dataset.y_names)\n",
    "            b_.append(y)\n",
    "        b = pd.concat(b_, axis=1)\n",
    "        if not show: return b\n",
    "        b = self.decode(b)\n",
    "        display_df(b)\n",
    "\n",
    "    def show_results(self, \n",
    "        b, # Batch to show results for\n",
    "        out, # Predicted output from model for the batch\n",
    "        max_n:int=9, # Maximum number of items to show\n",
    "        ctxs=None, # List of `ctx` objects to show data. Could be matplotlib axis, DataFrame etc\n",
    "        show:bool=True, # Whether to display data\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Show `max_n` results with input(s), target(s) and prediction(s).\"\n",
    "        df = self.show_batch(b, max_n=max_n, show=False)\n",
    "        yhat = pd.DataFrame(out[:max_n].cpu().numpy(), columns=[n+'_pred' for n in self.dataset.y_names])\n",
    "        if show: display_df(pd.concat([df, yhat], axis=1))\n",
    "\n",
    "TabularDask._dl_type = DaskDataLoader\n",
    "TabularDask._dbunch_type = DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example\n",
    "\n",
    "For a more in-depth explanation, see the [BigTabular tutorial](tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse              <NA>            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced              <NA>       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \n",
       "0   Female             0          1902              40   United-States  >=50k  \n",
       "1     Male         10520             0              45   United-States  >=50k  \n",
       "2   Female             0             0              32   United-States   <50k  \n",
       "3     Male             0             0              40   United-States  >=50k  \n",
       "4   Female             0             0              50   United-States   <50k  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n",
    "df_test.drop('salary', axis=1, inplace=True)\n",
    "ddf_main, ddf_test = dd.from_pandas(df_main), dd.from_pandas(df_test)\n",
    "ddf_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [DaskCategorify, DaskFillMissing, DaskNormalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularDask(\n",
    "    ddf_main, procs, cat_names, cont_names, y_names=\"salary\", train_mask_func=get_random_train_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1173107/2961782503.py:132: UserWarning: `shuffle` and `drop_last` are currently ignored.\n",
      "  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>96185.000419</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>284329.003227</td>\n",
       "      <td>9.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>267966.997633</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>213745.000003</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>23.999999</td>\n",
       "      <td>162593.001373</td>\n",
       "      <td>13.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>124071.002166</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>78858.996802</td>\n",
       "      <td>14.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>133298.999010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>54.000001</td>\n",
       "      <td>206963.999516</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = to.dataloaders()\n",
    "dls.valid.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>101320.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>236746.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>96185.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>38.0</td>\n",
       "      <td>112847.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>42.0</td>\n",
       "      <td>82297.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>63210.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44434.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>37.0</td>\n",
       "      <td>138940.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>46.0</td>\n",
       "      <td>328216.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>36.0</td>\n",
       "      <td>216711.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decode any set of transformed data by calling `to.decode_row` with our raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                49.0\n",
       "workclass                       Private\n",
       "fnlwgt                    101320.000758\n",
       "education                    Assoc-acdm\n",
       "education-num                      12.0\n",
       "marital-status       Married-civ-spouse\n",
       "occupation                         #na#\n",
       "relationship                       Wife\n",
       "race                              White\n",
       "sex                              Female\n",
       "capital-gain                          0\n",
       "capital-loss                       1902\n",
       "hours-per-week                       40\n",
       "native-country            United-States\n",
       "salary                              NaN\n",
       "_int_train_mask                    True\n",
       "education-num_na                  False\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = to.items.head().iloc[0]\n",
    "to.decode_row(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make new test datasets based on the training data with the `to.new()`\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "Since machine learning models can't magically understand categories it was never trained on, the data should reflect this. If there are different missing values in your test data you should address this before training\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>_int_train_mask</th>\n",
       "      <th>education-num_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.459802</td>\n",
       "      <td>5</td>\n",
       "      <td>1.338499</td>\n",
       "      <td>10</td>\n",
       "      <td>1.167323</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>-0.935224</td>\n",
       "      <td>5</td>\n",
       "      <td>1.251829</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.426158</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>1.047181</td>\n",
       "      <td>5</td>\n",
       "      <td>0.153621</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.222898</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>United-States</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.533224</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.277728</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.426158</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>United-States</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.753491</td>\n",
       "      <td>6</td>\n",
       "      <td>1.440618</td>\n",
       "      <td>9</td>\n",
       "      <td>0.370583</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  education-num  \\\n",
       "10000  0.459802          5  1.338499         10       1.167323   \n",
       "10001 -0.935224          5  1.251829         12      -0.426158   \n",
       "10002  1.047181          5  0.153621          2      -1.222898   \n",
       "10003  0.533224          5 -0.277728         12      -0.426158   \n",
       "10004  0.753491          6  1.440618          9       0.370583   \n",
       "\n",
       "       marital-status  occupation  relationship  race      sex  capital-gain  \\\n",
       "10000               3           2             1     2     Male             0   \n",
       "10001               3          15             1     4     Male             0   \n",
       "10002               1           9             2     5   Female             0   \n",
       "10003               7           2             5     5   Female             0   \n",
       "10004               3           5             1     5     Male             0   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country  _int_train_mask  \\\n",
       "10000             0              40     Philippines             True   \n",
       "10001             0              40   United-States             True   \n",
       "10002             0              37   United-States             True   \n",
       "10003             0              43   United-States             True   \n",
       "10004             0              60   United-States             True   \n",
       "\n",
       "       education-num_na  \n",
       "10000                 1  \n",
       "10001                 1  \n",
       "10002                 1  \n",
       "10003                 1  \n",
       "10004                 1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tst = to.new(ddf_test)\n",
    "to_tst.process()\n",
    "to_tst.items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert it to a `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>338105.004776</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>328662.996825</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>53.000001</td>\n",
       "      <td>209021.999291</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>162029.999826</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>349229.997941</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>124827.002017</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>53.000001</td>\n",
       "      <td>290639.999727</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>106273.002695</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>53683.997210</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst_dl = dls.valid.new(to_tst)\n",
    "tst_dl.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other target types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-label categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoded label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mock_multi_label(df):\n",
    "    sal,sex,white = [],[],[]\n",
    "    for row in df.itertuples():\n",
    "        sal.append(row.salary == '>=50k')\n",
    "        sex.append(row.sex == ' Male')\n",
    "        white.append(row.race == ' White')\n",
    "    df['salary'] = np.array(sal)\n",
    "    df['male']   = np.array(sex)\n",
    "    df['white']  = np.array(white)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n",
    "df_main = _mock_multi_label(df_main)\n",
    "ddf_main, ddf_test = dd.from_pandas(df_main), dd.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "      <th>male</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse              <NA>            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced              <NA>       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0   Female             0          1902              40   United-States   \n",
       "1     Male         10520             0              45   United-States   \n",
       "2   Female             0             0              32   United-States   \n",
       "3     Male             0             0              40   United-States   \n",
       "4   Female             0             0              50   United-States   \n",
       "\n",
       "   salary   male  white  \n",
       "0    True  False   True  \n",
       "1    True   True   True  \n",
       "2   False  False  False  \n",
       "3    True   True  False  \n",
       "4   False  False  False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@EncodedMultiCategorize\n",
    "def setups(self, to:Tabular):\n",
    "    self.c = len(self.vocab)\n",
    "    return self(to)\n",
    "\n",
    "@EncodedMultiCategorize\n",
    "def encodes(self, to:TabularDask): return to\n",
    "\n",
    "@EncodedMultiCategorize\n",
    "def decodes(self, to:TabularDask):\n",
    "    to.transform(to.y_names, lambda c: c==1)\n",
    "    return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [DaskCategorify, DaskFillMissing, DaskNormalize]\n",
    "y_names=[\"salary\", \"male\", \"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 976 ms, sys: 3.9 ms, total: 980 ms\n",
      "Wall time: 978 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "to = TabularDask(\n",
    "    ddf_main, procs, cat_names, cont_names, y_names=y_names, y_block=MultiCategoryBlock(encoded=True, vocab=y_names),\n",
    "    train_mask_func=get_random_train_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1173107/2961782503.py:132: UserWarning: `shuffle` and `drop_last` are currently ignored.\n",
      "  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "      <th>male</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>101320.001538</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>96185.002688</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>42.0</td>\n",
       "      <td>82296.993602</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>46.0</td>\n",
       "      <td>328215.996282</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>36.0</td>\n",
       "      <td>216710.999942</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>216283.999891</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>261293.002427</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>56.0</td>\n",
       "      <td>274110.999163</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Private</td>\n",
       "      <td>9th</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>46.0</td>\n",
       "      <td>117604.998708</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = to.dataloaders()\n",
    "dls.valid.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#### Not one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "def _mock_multi_label(df):\n",
    "    targ = []\n",
    "    for row in df.itertuples():\n",
    "        labels = []\n",
    "        if row.salary == '>=50k': labels.append('>50k')\n",
    "        if row.sex == ' Male':   labels.append('male')\n",
    "        if row.race == ' White': labels.append('white')\n",
    "        targ.append(' '.join(labels))\n",
    "    df['target'] = np.array(targ)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n",
    "df_main = _mock_multi_label(df_main)\n",
    "ddf_main, ddf_test = dd.from_pandas(df_main), dd.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "      <td>&gt;50k white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "      <td>&gt;50k male white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "      <td>&gt;50k male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse              <NA>            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced              <NA>       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \\\n",
       "0   Female             0          1902              40   United-States  >=50k   \n",
       "1     Male         10520             0              45   United-States  >=50k   \n",
       "2   Female             0             0              32   United-States   <50k   \n",
       "3     Male             0             0              40   United-States  >=50k   \n",
       "4   Female             0             0              50   United-States   <50k   \n",
       "\n",
       "            target  \n",
       "0       >50k white  \n",
       "1  >50k male white  \n",
       "2                   \n",
       "3        >50k male  \n",
       "4                   "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "ddf_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# @MultiCategorize\n",
    "# def encodes(self, to:Tabular):\n",
    "#     #to.transform(to.y_names, partial(_apply_cats, {n: self.vocab for n in to.y_names}, 0))\n",
    "#     return to\n",
    "\n",
    "# @MultiCategorize\n",
    "# def decodes(self, to:Tabular):\n",
    "#     #to.transform(to.y_names, partial(_decode_cats, {n: self.vocab for n in to.y_names}))\n",
    "#     return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "# cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "# procs = [Categorify, FillMissing, Normalize]\n",
    "# splits = RandomSplitter()(range_of(df_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# %time to = TabularPandas(df_main, procs, cat_names, cont_names, y_names=\"target\", y_block=MultiCategoryBlock(), splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# to.procs[2].vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "df_main,df_test = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n",
    "df_main = _mock_multi_label(df_main)\n",
    "ddf_main, ddf_test = dd.from_pandas(df_main), dd.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['fnlwgt', 'education-num']\n",
    "procs = [DaskCategorify, DaskFillMissing, DaskNormalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 802 ms, sys: 0 ns, total: 802 ms\n",
      "Wall time: 802 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "to = TabularDask(ddf_main, procs, cat_names, cont_names, y_names='age', train_mask_func=get_random_train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fnlwgt           192305.234512\n",
       "education-num        10.090168\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.procs[-1].means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1173107/2961782503.py:132: UserWarning: `shuffle` and `drop_last` are currently ignored.\n",
      "  warnings.warn('`shuffle` and `drop_last` are currently ignored.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>96185.001708</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>138940.000061</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>84661.004590</td>\n",
       "      <td>10.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>284328.998764</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>261292.999689</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>#na#</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>188942.000047</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>247294.003159</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>222614.998466</td>\n",
       "      <td>14.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>353824.002456</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = to.dataloaders()\n",
    "dls.valid.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
